{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86023,"databundleVersionId":11376393,"sourceType":"competition"},{"sourceId":97669,"databundleVersionId":11615683,"sourceType":"competition"},{"sourceId":166218,"sourceType":"modelInstanceVersion","modelInstanceId":141432,"modelId":164048},{"sourceId":166265,"sourceType":"modelInstanceVersion","modelInstanceId":141476,"modelId":164048}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":18109.463411,"end_time":"2025-05-10T12:24:19.582021","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-10T07:22:30.11861","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install bitsandbytes -q","metadata":{"execution":{"iopub.status.busy":"2025-05-11T10:20:42.033411Z","iopub.execute_input":"2025-05-11T10:20:42.033576Z","iopub.status.idle":"2025-05-11T10:21:51.657796Z","shell.execute_reply.started":"2025-05-11T10:20:42.033559Z","shell.execute_reply":"2025-05-11T10:21:51.657066Z"},"papermill":{"duration":67.178325,"end_time":"2025-05-10T07:23:41.677762","exception":false,"start_time":"2025-05-10T07:22:34.499437","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%writefile train.py\n\nimport os\nimport platform\nimport time\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nimport torch.multiprocessing as mp\nfrom torch.distributed import init_process_group, destroy_process_group\nfrom torch.amp import GradScaler\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\n\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig, get_cosine_schedule_with_warmup\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom transformers import BitsAndBytesConfig\n\n# ç¦ç”¨ tokenizer çš„å¤šçº¿ç¨‹è­¦å‘Šï¼Œé¿å…å¤šè¿›ç¨‹å†²çªæˆ–æŽ§åˆ¶å°è­¦å‘Š\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\n\n# ========= æ¨¡åž‹ä¸Žè®­ç»ƒçš„å¸¸é‡å®šä¹‰ =========\nmodel_path = '/kaggle/input/qwen2.5/transformers/14b/1'  # Qwen2.5-14B æ¨¡åž‹è·¯å¾„\nnum_folds = 3                 # 3æŠ˜äº¤å‰éªŒè¯\nnum_epochs = 3                # æ¯æŠ˜è®­ç»ƒ3è½®\nbatch_size = 2                # æ¯å¡æ¯æ­¥å¤„ç†2æ¡æ ·æœ¬\ngrad_accum_steps = 8          # æ¢¯åº¦ç´¯è®¡8æ­¥ï¼Œç›¸å½“äºŽæœ‰æ•ˆ batch size ä¸º 2Ã—8=16\n\n# åŠ è½½ Qwen tokenizerï¼Œå¹¶è®¾ç½®ä¸ºå·¦ä¾§ paddingï¼ˆé€‚åˆ decoder-only æ¨¡åž‹ï¼‰\ntokenizer = AutoTokenizer.from_pretrained(model_path)\ntokenizer.padding_side = 'left'\n\n\nclass MathDataset(Dataset):\n    def __init__(self, prompts, targets):\n        self.prompts = prompts      # prompt æ˜¯æ¨¡åž‹çš„æ–‡æœ¬è¾“å…¥ï¼ˆå¦‚ï¼šClassify the topic of this problem: ...ï¼‰\n        self.targets = targets      # targets æ˜¯å¯¹åº”çš„æ ‡ç­¾ï¼ˆæ•´æ•°ï¼Œ0~7ï¼‰\n\n    def __getitem__(self, idx):\n        return self.prompts[idx], self.targets[idx]  # æ”¯æŒé€šè¿‡ç´¢å¼•å–å‡ºä¸€ç»„æ ·æœ¬\n\n    def __len__(self):\n        return len(self.targets)    # æ•°æ®é›†æ€»é•¿åº¦\n\n\nclass Net(nn.Module):\n    def __init__(self, model_path, rank):\n        super(Net, self).__init__()\n        # è¯»å–æ¨¡åž‹é…ç½®ï¼ˆå¦‚ hidden_sizeã€å±‚æ•°ç­‰ï¼‰\n        self.config = AutoConfig.from_pretrained(model_path)\n\n\n        # ä½¿ç”¨ bitsandbytes è¿›è¡Œ 4bit é‡åŒ–åŠ è½½é…ç½®ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰\n        bnb_config = BitsAndBytesConfig(\n            load_in_4bit=True,                       # å¯ç”¨ 4bit æƒé‡é‡åŒ–\n            bnb_4bit_use_double_quant=True,          # åŒé‡é‡åŒ–ä»¥è¿›ä¸€æ­¥åŽ‹ç¼©\n            bnb_4bit_quant_type=\"nf4\",               # nf4 æ˜¯éžå¯¹ç§°é‡åŒ–ï¼ˆæ›´å¼ºè¡¨è¾¾èƒ½åŠ›ï¼‰\n            bnb_4bit_compute_dtype=torch.float16     # ä½¿ç”¨ float16 è¿›è¡Œå‰å‘/åå‘è®¡ç®—\n        )\n\n\n        # åŠ è½½ Qwen æ¨¡åž‹ä¸»å¹²ï¼ˆä¸å¸¦è¯­è¨€æ¨¡åž‹å¤´ï¼‰ï¼Œé‡‡ç”¨é‡åŒ–åŠ è½½æ–¹å¼\n        self.backbone = AutoModel.from_pretrained(\n            model_path,\n            use_cache=False,                   # ä¸ä½¿ç”¨ç¼“å­˜ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰\n            torch_dtype=torch.float16,         # æ¨¡åž‹ç”¨ float16 æŽ¨ç†\n            quantization_config=bnb_config,    # ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„ 4bit é‡åŒ–ç­–ç•¥\n            device_map=rank                    # æŒ‡å®š GPU ç¼–å·ï¼ˆç”¨äºŽ DDPï¼‰\n        )\n\n\n        # å®šä¹‰ LoRA é…ç½®ï¼šå¯¹æ‰€æœ‰çº¿æ€§å±‚æ³¨å…¥ r=8 çš„ä½Žç§©ç»“æž„\n        peft_config = LoraConfig(\n            task_type=TaskType.FEATURE_EXTRACTION,  # LoRA ç±»åž‹ä¸ºç‰¹å¾æŠ½å–ï¼ˆéžç”Ÿæˆï¼‰\n            target_modules='all-linear',            # åº”ç”¨äºŽæ‰€æœ‰çº¿æ€§å±‚\n            bias='none',                            # ä¸å¼•å…¥é¢å¤– bias\n            inference_mode=False,                   # å¼€å¯è®­ç»ƒæ¨¡å¼\n            r=8,                                     # LoRA çš„ç§©ï¼ˆå­ç©ºé—´ç»´åº¦ï¼‰\n            lora_alpha=16,                          # æ”¾ç¼©å› å­\n            lora_dropout=0.05                       # Dropout é˜²æ­¢è¿‡æ‹Ÿåˆ\n        )\n\n        # å°†ä¸»å¹²æ¨¡åž‹è½¬æ¢ä¸º LoRA å¯è®­ç»ƒæ¨¡åž‹\n        self.backbone = get_peft_model(self.backbone, peft_config)\n\n        self.head = nn.Linear(self.config.hidden_size, 8, bias=False)\n\n    def forward(self, x):\n        # ä½¿ç”¨ Qwen æ¨¡åž‹èŽ·å–æœ€åŽä¸€å±‚æ‰€æœ‰ token çš„è¾“å‡º\n        x = self.backbone(**x).last_hidden_state[:, -1, :]\n        # å–æœ€åŽä¸€ä¸ª token çš„å‘é‡ï¼ˆå› ä¸ºæ˜¯å·¦ paddingï¼Œæœ€åŽä¸€ä¸ªæ˜¯è¾“å…¥æœ«å°¾ï¼‰\n        return self.head(x)  # æŠ•å½±åˆ° 8 ç»´ä½œä¸º logits è¾“å‡º\n\n\ndef ddp_setup(rank, world_size):\n    # è®¾ç½®ä¸»è¿›ç¨‹çš„åœ°å€å’Œç«¯å£ï¼ˆç”¨äºŽå„ GPU ä¹‹é—´é€šä¿¡ï¼‰\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n\n    # å¦‚æžœæ˜¯ Windows ç³»ç»Ÿï¼Œä½¿ç”¨ GLOO åŽç«¯ï¼ˆWindows ä¸æ”¯æŒ NCCLï¼‰\n    if platform.system() == 'Windows':\n        os.environ['USE_LIBUV'] = '0'  # é¿å…ä¸Ž LibUV å†²çª\n        init_process_group(backend='gloo', rank=rank, world_size=world_size)\n    else:\n        # Linux æˆ–å…¶ä»–ç³»ç»Ÿï¼Œä½¿ç”¨ NCCLï¼ˆGPU é—´é€šä¿¡æ›´å¿«ï¼‰\n        init_process_group(backend='nccl', rank=rank, world_size=world_size)\n\n    # æŒ‡å®šå½“å‰è¿›ç¨‹ä½¿ç”¨å“ªå¼  GPUï¼ˆæ¯ä¸ª rank å¯¹åº”ä¸€ä¸ª GPUï¼‰\n    torch.cuda.set_device(rank)\n\n\ndef get_optimizer(model, learning_rate=0.0001, diff_lr=0.00001, weight_decay=0.01):\n    # ä¸è¿›è¡Œæƒé‡è¡°å‡çš„å‚æ•°ï¼ˆå¦‚ LayerNorm å’Œ biasï¼‰\n    no_decay = ['bias', 'LayerNorm.weight']\n    \n    # éœ€è¦è®¾ç½®â€œä½Žå­¦ä¹ çŽ‡â€çš„æ¨¡å—ï¼ˆå¦‚å¤§æ¨¡åž‹ä¸»å¹²éƒ¨åˆ†ï¼‰\n    differential_layers = ['backbone']\n\n    optimizer = torch.optim.AdamW(\n        [\n            # ðŸ”¹1. ä¸»å¹²ä¹‹å¤–ï¼Œä¸”éœ€è¦ weight decay çš„å‚æ•°\n            {\n                \"params\": [\n                    param for name, param in model.named_parameters()\n                    if (not any(layer in name for layer in differential_layers)) and\n                       (not any(nd in name for nd in no_decay))\n                ],\n                \"lr\": learning_rate,\n                \"weight_decay\": weight_decay,\n            },\n            # ðŸ”¹2. ä¸»å¹²ä¹‹å¤–ï¼Œä½†ä¸éœ€è¦ weight decay çš„å‚æ•°ï¼ˆå¦‚ LayerNormã€biasï¼‰\n            {\n                \"params\": [\n                    param for name, param in model.named_parameters()\n                    if (not any(layer in name for layer in differential_layers)) and\n                       (any(nd in name for nd in no_decay))\n                ],\n                \"lr\": learning_rate,\n                \"weight_decay\": 0,\n            },\n            # ðŸ”¹3. ä¸»å¹²å†…ï¼Œä¸”éœ€è¦ weight decay çš„å‚æ•°ï¼ˆä¾‹å¦‚ encoder layersï¼‰\n            {\n                \"params\": [\n                    param for name, param in model.named_parameters()\n                    if (any(layer in name for layer in differential_layers)) and\n                       (not any(nd in name for nd in no_decay))\n                ],\n                \"lr\": diff_lr,\n                \"weight_decay\": weight_decay,\n            },\n            # ðŸ”¹4. ä¸»å¹²å†…ï¼Œä¸éœ€è¦ weight decay çš„å‚æ•°\n            {\n                \"params\": [\n                    param for name, param in model.named_parameters()\n                    if (any(layer in name for layer in differential_layers)) and\n                       (any(nd in name for nd in no_decay))\n                ],\n                \"lr\": diff_lr,\n                \"weight_decay\": 0,\n            },\n        ],\n        lr=learning_rate,           # é»˜è®¤å­¦ä¹ çŽ‡ï¼ˆä¼ ç»™ optimizerï¼Œç”¨äºŽå…¼å®¹æ€§ï¼‰\n        weight_decay=weight_decay, # é»˜è®¤ weight decayï¼ˆä¸€èˆ¬ä¸ç”Ÿæ•ˆï¼Œå› ä¸ºå·²åˆ†ç»„ï¼‰\n    )\n\n    return optimizer\n\n\ndef train_model(rank, world_size, num_epochs, fold, train_index, val_index, all_prompts, all_targets):\n    ddp_setup(rank, world_size)\n\n    train_prompts = [all_prompts[i] for i in train_index]\n    val_prompts = [all_prompts[i] for i in val_index]\n    train_targets = [all_targets[i] for i in train_index]\n    val_targets = [all_targets[i] for i in val_index]\n\n    class_weights = 1 / (np.unique(train_targets, return_counts=True)[1] / len(train_targets)) #ç±»åˆ«è¶Šç¨€æœ‰ï¼Œæƒé‡è¶Šå¤§ï¼ˆä½¿å…¶ loss æ›´é‡è¦ï¼‰\n    class_weights = torch.tensor(class_weights, dtype=torch.half)\n\n    train_dataset = MathDataset(train_prompts, train_targets)\n    val_dataset = MathDataset(val_prompts, val_targets)\n\n    train_sampler = DistributedSampler(train_dataset)  #æ¯å¼  GPU é‡‡æ ·ä¸åŒæ•°æ®ï¼Œä¿è¯æ•°æ®ä¸é‡å¤\n    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, sampler=train_sampler, pin_memory=True, shuffle=False, drop_last=True)\n    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size*2, shuffle=False, drop_last=False)\n\n    model = Net(model_path, rank).to(rank)\n    model = DDP(model, device_ids=[rank])\n\n    optimizer = get_optimizer(model, learning_rate=2e-4, diff_lr=2e-4, weight_decay=0.01)\n\n    scheduler = get_cosine_schedule_with_warmup(optimizer=optimizer,\n                                                num_warmup_steps=0, \n                                                num_training_steps=(len(train_loader) // grad_accum_steps) * num_epochs)\n    scaler = GradScaler()\n\n    best_f1 = 0.0\n    MAX_LEN = 400\n\n    for epoch in range(num_epochs):\n        train_loader.sampler.set_epoch(epoch)\n        model.train()\n        optimizer.zero_grad()\n\n        for step, (batch_prompts, batch_targets) in enumerate(tqdm(train_loader)):\n            max_len = max(len(x) for x in tokenizer(batch_prompts).input_ids)\n\n            encodings = tokenizer(batch_prompts,\n                                  return_tensors='pt',\n                                  padding='max_length' if max_len > MAX_LEN else 'longest',\n                                  truncation=max_len > MAX_LEN,\n                                  max_length=MAX_LEN).to(rank)\n\n            batch_targets = batch_targets.long().to(rank)\n\n            with torch.autocast(device_type='cuda', dtype=torch.float16):\n                logits = model(encodings)\n                loss = F.cross_entropy(logits, batch_targets, weight=class_weights.to(rank))\n                loss = loss / grad_accum_steps\n\n            scaler.scale(loss).backward()\n\n            if (step + 1) % grad_accum_steps == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n                scheduler.step()\n\n        # Validation\n        model.eval()\n        all_preds, all_labels = [], []\n        with torch.no_grad():\n            for batch_prompts, batch_targets in tqdm(val_loader, total=len(val_loader)):\n                max_len = max(len(x) for x in tokenizer(batch_prompts).input_ids)\n\n                encodings = tokenizer(batch_prompts,\n                                      return_tensors='pt',\n                                      padding='max_length' if max_len > MAX_LEN else 'longest',\n                                      truncation=max_len > MAX_LEN,\n                                      max_length=MAX_LEN).to(rank)\n\n                with torch.autocast(device_type='cuda', dtype=torch.float16):\n                    logits = model(encodings)\n                    preds = torch.argmax(logits, dim=1).cpu().tolist()\n\n                all_preds.extend(preds)\n                all_labels.extend(batch_targets)\n\n        f1 = f1_score(all_labels, all_preds, average='micro')\n        print(f'[GPU {rank}] Fold {fold+1} | Epoch {epoch+1}/{num_epochs} | Val F1-micro: {f1:.4f}')\n\n        if rank == 0 and f1 > best_f1:\n            best_f1 = f1\n            model.eval()\n            model.module.backbone.save_pretrained(f'backbone_fold_{fold}_best')\n            torch.save(model.module.head.state_dict(), f'head_fold_{fold}_best.pt')\n\n    destroy_process_group()\n\ndef run_ddp(rank, world_size, num_epochs, splits, fold, all_prompts, all_targets):\n    train_index, val_index = splits[fold]\n    train_model(rank, world_size, num_epochs, fold, train_index, val_index, all_prompts, all_targets)\n\nif __name__ == '__main__':\n    print(\"PyTorch version:\", torch.__version__)\n    print(\"CUDA available:\", torch.cuda.is_available())\n    print(\"Number of GPUs available:\", torch.cuda.device_count())\n\n    seed = 252\n    torch.manual_seed(seed)\n\n    df = pd.read_csv('/kaggle/input/classification-of-math-problems-by-kasut-academy/train.csv')\n    df.columns = ['problem', 'target']\n\n    prompts = [\n        f\"\"\"'<|im_start|>user\nYour task is to classify each Math problem into one of these eight topics using a machine learning or NLP-based approach.\n0: Algebra\n1: Geometry and Trigonometry\n2: Calculus and Analysis\n3: Probability and Statistics\n4: Number Theory\n5: Combinatorics and Discrete Math\n6: Linear Algebra\n7: Abstract Algebra and Topology\n\nYour answer should be an integer that assigns the most appropriate topic category to the given Math problem based on its content and required reasoning.\n\nMath Problem: {tokenizer.decode(tokenizer(p.strip(), return_tensors='pt', padding='max_length', max_length=300, truncation=True).input_ids[0], skip_special_tokens=True)}\n\nAnswer: \"\"\"\n        for p in df['problem']\n    ]\n\n    targets = df['target'].tolist()\n\n    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed)\n    splits = list(skf.split(prompts, targets))\n\n    world_size = torch.cuda.device_count()\n\n    for fold in range(num_folds):\n        mp.spawn(run_ddp, args=(world_size, num_epochs, splits, fold, prompts, targets), nprocs=world_size)\n","metadata":{"execution":{"iopub.status.busy":"2025-05-11T10:23:26.907165Z","iopub.execute_input":"2025-05-11T10:23:26.907846Z","iopub.status.idle":"2025-05-11T10:23:26.918821Z","shell.execute_reply.started":"2025-05-11T10:23:26.907821Z","shell.execute_reply":"2025-05-11T10:23:26.918291Z"},"papermill":{"duration":0.024534,"end_time":"2025-05-10T07:23:41.716783","exception":false,"start_time":"2025-05-10T07:23:41.692249","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Writing train.py\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!python train.py","metadata":{"execution":{"iopub.status.busy":"2025-05-11T10:23:35.497574Z","iopub.execute_input":"2025-05-11T10:23:35.498215Z","iopub.status.idle":"2025-05-11T15:32:12.585686Z","shell.execute_reply.started":"2025-05-11T10:23:35.498194Z","shell.execute_reply":"2025-05-11T15:32:12.584916Z"},"papermill":{"duration":18030.634037,"end_time":"2025-05-10T12:24:12.364932","exception":false,"start_time":"2025-05-10T07:23:41.730895","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"2025-05-11 10:23:48.906993: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746959029.139072     180 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746959029.207550     180 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nPyTorch version: 2.5.1+cu124\nCUDA available: True\nNumber of GPUs available: 4\n2025-05-11 10:24:12.469980: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746959052.492010     248 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746959052.498755     248 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-05-11 10:24:20.639444: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746959060.660963     315 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746959060.667552     315 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nSliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\nLoading checkpoint shards:   0%|                          | 0/8 [00:00<?, ?it/s]2025-05-11 10:24:28.933412: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746959068.956053     381 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746959068.962922     381 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nSliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\nLoading checkpoint shards:   0%|                          | 0/8 [00:00<?, ?it/s]2025-05-11 10:24:37.205621: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746959077.227748     457 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746959077.234502     457 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nSliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\nSliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\nLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [07:23<00:00, 55.39s/it]\nLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [07:23<00:00, 55.40s/it]\n\nLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [07:31<00:00, 56.41s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:16<00:00,  1.36s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:16<00:00,  1.36s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:16<00:00,  1.36s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:16<00:00,  1.36s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [13:20<00:00,  1.06it/s]\n[GPU 3] Fold 1 | Epoch 1/3 | Val F1-micro: 0.8961\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [13:25<00:00,  1.05it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 847/850 [13:25<00:03,  1.03s/it][GPU 2] Fold 1 | Epoch 1/3 | Val F1-micro: 0.8961\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [13:27<00:00,  1.05it/s]\n[GPU 0] Fold 1 | Epoch 1/3 | Val F1-micro: 0.8961\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [13:54<00:00,  1.02it/s]\n[GPU 1] Fold 1 | Epoch 1/3 | Val F1-micro: 0.8961\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:36<00:00,  1.39s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:31<00:00,  1.38s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:29<00:00,  1.38s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:02<00:00,  1.35s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [13:21<00:00,  1.06it/s]\n 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 816/850 [13:21<00:34,  1.01s/it][GPU 3] Fold 1 | Epoch 2/3 | Val F1-micro: 0.8990\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [13:25<00:00,  1.05it/s]\n[GPU 2] Fold 1 | Epoch 2/3 | Val F1-micro: 0.8990\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [13:27<00:00,  1.05it/s]\n[GPU 0] Fold 1 | Epoch 2/3 | Val F1-micro: 0.8990\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [13:55<00:00,  1.02it/s]\n[GPU 1] Fold 1 | Epoch 2/3 | Val F1-micro: 0.8990\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:30<00:00,  1.38s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:28<00:00,  1.38s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:01<00:00,  1.34s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:35<00:00,  1.38s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [13:20<00:00,  1.06it/s]\n[GPU 3] Fold 1 | Epoch 3/3 | Val F1-micro: 0.9096\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [13:25<00:00,  1.05it/s]\n[GPU 2] Fold 1 | Epoch 3/3 | Val F1-micro: 0.9096\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [13:27<00:00,  1.05it/s]\n[GPU 0] Fold 1 | Epoch 3/3 | Val F1-micro: 0.9096\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 850/850 [13:55<00:00,  1.02it/s]\n[GPU 1] Fold 1 | Epoch 3/3 | Val F1-micro: 0.9096\n2025-05-11 12:11:23.223131: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746965483.245061     680 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746965483.251694     680 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-05-11 12:11:31.518180: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746965491.540081     747 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746965491.546769     747 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nSliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\nLoading checkpoint shards:   0%|                          | 0/8 [00:00<?, ?it/s]2025-05-11 12:11:39.860100: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746965499.881893     816 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746965499.888519     816 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLoading checkpoint shards:  12%|â–ˆâ–ˆâ–Ž               | 1/8 [00:03<00:26,  3.72s/it]Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\nLoading checkpoint shards:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 2/8 [00:09<00:28,  4.72s/it]2025-05-11 12:11:48.320812: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746965508.343420     889 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746965508.350257     889 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLoading checkpoint shards:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 3/8 [00:14<00:25,  5.03s/it]Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\nSliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\nLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:36<00:00,  4.60s/it]\nLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:36<00:00,  4.57s/it]\nLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:36<00:00,  4.58s/it]\nLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:36<00:00,  4.57s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:17<00:00,  1.36s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:17<00:00,  1.36s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:17<00:00,  1.36s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:18<00:00,  1.36s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:17<00:00,  1.06it/s]\n[GPU 3] Fold 2 | Epoch 1/3 | Val F1-micro: 0.8634\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:20<00:00,  1.06it/s]\n[GPU 2] Fold 2 | Epoch 1/3 | Val F1-micro: 0.8634\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:26<00:00,  1.05it/s]\n 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 823/849 [13:26<00:25,  1.04it/s][GPU 0] Fold 2 | Epoch 1/3 | Val F1-micro: 0.8634\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:50<00:00,  1.02it/s]\n[GPU 1] Fold 2 | Epoch 1/3 | Val F1-micro: 0.8634\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:36<00:00,  1.39s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:29<00:00,  1.38s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:05<00:00,  1.35s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:40<00:00,  1.39s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:16<00:00,  1.07it/s]\n[GPU 3] Fold 2 | Epoch 2/3 | Val F1-micro: 0.9022\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:19<00:00,  1.06it/s]\n[GPU 2] Fold 2 | Epoch 2/3 | Val F1-micro: 0.9022\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:25<00:00,  1.05it/s]\n[GPU 0] Fold 2 | Epoch 2/3 | Val F1-micro: 0.9022\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:51<00:00,  1.02it/s]\n[GPU 1] Fold 2 | Epoch 2/3 | Val F1-micro: 0.9022\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:37<00:00,  1.39s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:35<00:00,  1.38s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:28<00:00,  1.38s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:03<00:00,  1.35s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:16<00:00,  1.07it/s]\n[GPU 3] Fold 2 | Epoch 3/3 | Val F1-micro: 0.9108\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:19<00:00,  1.06it/s]\n[GPU 2] Fold 2 | Epoch 3/3 | Val F1-micro: 0.9108\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:25<00:00,  1.05it/s]\n[GPU 0] Fold 2 | Epoch 3/3 | Val F1-micro: 0.9108\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:50<00:00,  1.02it/s]\n[GPU 1] Fold 2 | Epoch 3/3 | Val F1-micro: 0.9108\n2025-05-11 13:51:40.306602: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746971500.328848    1112 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746971500.335884    1112 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-05-11 13:51:48.787134: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746971508.809300    1179 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746971508.816136    1179 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nSliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\nLoading checkpoint shards:   0%|                          | 0/8 [00:00<?, ?it/s]2025-05-11 13:51:57.188937: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746971517.210937    1248 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746971517.217682    1248 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLoading checkpoint shards:  12%|â–ˆâ–ˆâ–Ž               | 1/8 [00:03<00:25,  3.70s/it]Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\nLoading checkpoint shards:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 2/8 [00:09<00:28,  4.72s/it]2025-05-11 13:52:05.717862: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746971525.739666    1321 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746971525.746308    1321 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLoading checkpoint shards:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 3/8 [00:14<00:25,  5.04s/it]Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\nSliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\nLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:36<00:00,  4.60s/it]\nLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:36<00:00,  4.62s/it]\nLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:36<00:00,  4.59s/it]\nLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:36<00:00,  4.59s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:12<00:00,  1.36s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:12<00:00,  1.36s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:12<00:00,  1.36s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:13<00:00,  1.36s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:21<00:00,  1.06it/s]\n[GPU 3] Fold 3 | Epoch 1/3 | Val F1-micro: 0.8657\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:24<00:00,  1.06it/s]\n[GPU 2] Fold 3 | Epoch 1/3 | Val F1-micro: 0.8657\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:29<00:00,  1.05it/s]\n[GPU 0] Fold 3 | Epoch 1/3 | Val F1-micro: 0.8657\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:58<00:00,  1.01it/s]\n[GPU 1] Fold 3 | Epoch 1/3 | Val F1-micro: 0.8657\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:44<00:00,  1.40s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:40<00:00,  1.39s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:06<00:00,  1.35s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:35<00:00,  1.39s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:22<00:00,  1.06it/s]\n[GPU 3] Fold 3 | Epoch 2/3 | Val F1-micro: 0.8996\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:24<00:00,  1.06it/s]\n[GPU 2] Fold 3 | Epoch 2/3 | Val F1-micro: 0.8996\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:30<00:00,  1.05it/s]\n[GPU 0] Fold 3 | Epoch 2/3 | Val F1-micro: 0.8996\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:58<00:00,  1.01it/s]\n[GPU 1] Fold 3 | Epoch 2/3 | Val F1-micro: 0.8996\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:36<00:00,  1.39s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:39<00:00,  1.39s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:30<00:00,  1.38s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [19:02<00:00,  1.35s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:21<00:00,  1.06it/s]\n[GPU 3] Fold 3 | Epoch 3/3 | Val F1-micro: 0.9043\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:24<00:00,  1.06it/s]\n 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 813/849 [13:24<00:41,  1.15s/it][GPU 2] Fold 3 | Epoch 3/3 | Val F1-micro: 0.9043\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:29<00:00,  1.05it/s]\n 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 819/849 [13:29<00:28,  1.06it/s][GPU 0] Fold 3 | Epoch 3/3 | Val F1-micro: 0.9043\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [13:58<00:00,  1.01it/s]\n[GPU 1] Fold 3 | Epoch 3/3 | Val F1-micro: 0.9043\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":2.409747,"end_time":"2025-05-10T12:24:16.958793","exception":false,"start_time":"2025-05-10T12:24:14.549046","status":"completed"},"tags":[]},"outputs":[],"execution_count":null}]}