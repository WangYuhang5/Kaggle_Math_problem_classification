{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86023,"databundleVersionId":11376393,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":97669,"databundleVersionId":11615683,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":11680805,"sourceType":"datasetVersion","datasetId":7331162},{"sourceId":11680822,"sourceType":"datasetVersion","datasetId":7331167},{"sourceId":11689087,"sourceType":"datasetVersion","datasetId":7336633},{"sourceId":11689110,"sourceType":"datasetVersion","datasetId":7336648},{"sourceId":11689121,"sourceType":"datasetVersion","datasetId":7336657},{"sourceId":11689146,"sourceType":"datasetVersion","datasetId":7336674},{"sourceId":11759534,"sourceType":"datasetVersion","datasetId":7382355},{"sourceId":11760573,"sourceType":"datasetVersion","datasetId":7383040},{"sourceId":11760605,"sourceType":"datasetVersion","datasetId":7383062},{"sourceId":11760635,"sourceType":"datasetVersion","datasetId":7383084},{"sourceId":11760643,"sourceType":"datasetVersion","datasetId":7383090},{"sourceId":11760681,"sourceType":"datasetVersion","datasetId":7383117},{"sourceId":181362386,"sourceType":"kernelVersion"},{"sourceId":181362455,"sourceType":"kernelVersion"},{"sourceId":181362471,"sourceType":"kernelVersion"},{"sourceId":238959786,"sourceType":"kernelVersion"},{"sourceId":166265,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":141476,"modelId":164048},{"sourceId":363149,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":301527,"modelId":322000}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install /kaggle/input/bitsandbytes-pip-download/bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl -q\n!pip install /kaggle/input/accelerate-pip-download/accelerate-0.30.1-py3-none-any.whl -q\n!pip install --no-index --find-links=/kaggle/input/install-peft peft -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:23:31.638094Z","iopub.execute_input":"2025-05-12T08:23:31.638868Z","iopub.status.idle":"2025-05-12T08:23:35.973941Z","shell.execute_reply.started":"2025-05-12T08:23:31.638844Z","shell.execute_reply":"2025-05-12T08:23:35.972994Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Requirement '/kaggle/input/bitsandbytes-pip-download/bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/kaggle/input/bitsandbytes-pip-download/bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl'\n\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Requirement '/kaggle/input/accelerate-pip-download/accelerate-0.30.1-py3-none-any.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/kaggle/input/accelerate-pip-download/accelerate-0.30.1-py3-none-any.whl'\n\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Location '/kaggle/input/install-peft' is ignored: it is either a non-existing path or lacks a specific scheme.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Location '/kaggle/input/install-peft' is ignored: it is either a non-existing path or lacks a specific scheme.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Location '/kaggle/input/install-peft' is ignored: it is either a non-existing path or lacks a specific scheme.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Location '/kaggle/input/install-peft' is ignored: it is either a non-existing path or lacks a specific scheme.\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" (from torch) (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\"\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!pip install -U bitsandbytes accelerate peft -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:28:24.817833Z","iopub.execute_input":"2025-05-12T08:28:24.818091Z","iopub.status.idle":"2025-05-12T08:29:35.776756Z","shell.execute_reply.started":"2025-05-12T08:28:24.818067Z","shell.execute_reply":"2025-05-12T08:29:35.776105Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport gc\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom transformers import AutoTokenizer, AutoConfig\nfrom transformers import AutoModel, AutoModelForCausalLM\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.amp import GradScaler, autocast\n\nfrom peft import (\n    get_peft_config, \n    get_peft_model, \n    LoraConfig,\n    TaskType,\n     prepare_model_for_kbit_training\n)\n\nfrom transformers import BitsAndBytesConfig\nfrom transformers import get_cosine_schedule_with_warmup\n\nfrom sentence_transformers import SentenceTransformer\nfrom peft import AutoPeftModelForFeatureExtraction\n\nimport ctypes\nimport os\n\nfrom threading import Thread\nfrom tqdm.notebook import tqdm\n\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\nos.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:29:38.852945Z","iopub.execute_input":"2025-05-12T08:29:38.853449Z","iopub.status.idle":"2025-05-12T08:30:06.782210Z","shell.execute_reply.started":"2025-05-12T08:29:38.853422Z","shell.execute_reply":"2025-05-12T08:30:06.781612Z"}},"outputs":[{"name":"stderr","text":"2025-05-12 08:29:52.211660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747038592.456555      73 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747038592.526532      73 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def clean_memory(deep=True):\n    gc.collect()\n    if deep:\n        ctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n    torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:30:14.445928Z","iopub.execute_input":"2025-05-12T08:30:14.446900Z","iopub.status.idle":"2025-05-12T08:30:14.450117Z","shell.execute_reply.started":"2025-05-12T08:30:14.446877Z","shell.execute_reply":"2025-05-12T08:30:14.449582Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/classification-of-math-problems-by-kasut-academy/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:30:16.421492Z","iopub.execute_input":"2025-05-12T08:30:16.422158Z","iopub.status.idle":"2025-05-12T08:30:16.454793Z","shell.execute_reply.started":"2025-05-12T08:30:16.422134Z","shell.execute_reply":"2025-05-12T08:30:16.454263Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"test.columns = ['id', 'problem']\n\nprompts = [\n    f\"\"\"'<|im_start|>user\nYour task is to classify each Math problem into one of these eight topics using a machine learning or NLP-based approach.\n0: Algebra\n1: Geometry and Trigonometry\n2: Calculus and Analysis\n3: Probability and Statistics\n4: Number Theory\n5: Combinatorics and Discrete Math\n6: Linear Algebra\n7: Abstract Algebra and Topology\n\nYour answer should be an integer that assigns the most appropriate topic category to the given Math problem based on its content and required reasoning.\n\nMath Problem: {p.strip()}\n\nAnswer: \"\"\"\n    for p in test['problem']\n]\n\ntest['problem'] = prompts\ntest['target'] = -100\ntest","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:30:17.776932Z","iopub.execute_input":"2025-05-12T08:30:17.777529Z","iopub.status.idle":"2025-05-12T08:30:17.805583Z","shell.execute_reply.started":"2025-05-12T08:30:17.777509Z","shell.execute_reply":"2025-05-12T08:30:17.805098Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        id                                            problem  target\n0        0  '<|im_start|>user\\nYour task is to classify ea...    -100\n1        1  '<|im_start|>user\\nYour task is to classify ea...    -100\n2        2  '<|im_start|>user\\nYour task is to classify ea...    -100\n3        3  '<|im_start|>user\\nYour task is to classify ea...    -100\n4        4  '<|im_start|>user\\nYour task is to classify ea...    -100\n...    ...                                                ...     ...\n3039  3039  '<|im_start|>user\\nYour task is to classify ea...    -100\n3040  3040  '<|im_start|>user\\nYour task is to classify ea...    -100\n3041  3041  '<|im_start|>user\\nYour task is to classify ea...    -100\n3042  3042  '<|im_start|>user\\nYour task is to classify ea...    -100\n3043  3043  '<|im_start|>user\\nYour task is to classify ea...    -100\n\n[3044 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>problem</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>'&lt;|im_start|&gt;user\\nYour task is to classify ea...</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>'&lt;|im_start|&gt;user\\nYour task is to classify ea...</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>'&lt;|im_start|&gt;user\\nYour task is to classify ea...</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>'&lt;|im_start|&gt;user\\nYour task is to classify ea...</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>'&lt;|im_start|&gt;user\\nYour task is to classify ea...</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3039</th>\n      <td>3039</td>\n      <td>'&lt;|im_start|&gt;user\\nYour task is to classify ea...</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>3040</th>\n      <td>3040</td>\n      <td>'&lt;|im_start|&gt;user\\nYour task is to classify ea...</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>3041</th>\n      <td>3041</td>\n      <td>'&lt;|im_start|&gt;user\\nYour task is to classify ea...</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>3042</th>\n      <td>3042</td>\n      <td>'&lt;|im_start|&gt;user\\nYour task is to classify ea...</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>3043</th>\n      <td>3043</td>\n      <td>'&lt;|im_start|&gt;user\\nYour task is to classify ea...</td>\n      <td>-100</td>\n    </tr>\n  </tbody>\n</table>\n<p>3044 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"model_path = '/kaggle/input/qwen-3/transformers/14b/1'\n\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\ntokenizer.padding_side = 'left'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:30:20.244674Z","iopub.execute_input":"2025-05-12T08:30:20.245251Z","iopub.status.idle":"2025-05-12T08:30:20.833497Z","shell.execute_reply.started":"2025-05-12T08:30:20.245223Z","shell.execute_reply":"2025-05-12T08:30:20.832947Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"test['problem'].apply(lambda x:len( tokenizer(x).input_ids)).hist();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:30:22.220178Z","iopub.execute_input":"2025-05-12T08:30:22.220414Z","iopub.status.idle":"2025-05-12T08:30:24.189747Z","shell.execute_reply.started":"2025-05-12T08:30:22.220398Z","shell.execute_reply":"2025-05-12T08:30:24.189223Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApa0lEQVR4nO3de3SU5YHH8V+uk0SYhIDJJDXEVFsuchUUpirFEhIwi1o5uwsiUEv1wCZdYywiVZHL2rBYtdpFWLdVukdQ9BylCixkCAKi4ZYSuagpKja2MGEXTIZrGMizf3jy1pGLZJwQnuT7OScH5n2feed5fhnld9553yTKGGMEAABgkejWngAAAEBzUWAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKxDgQEAANaJbe0JtJTGxkbt27dPHTt2VFRUVGtPBwAAXABjjA4fPqzMzExFR5/7PEubLTD79u1TVlZWa08DAACE4fPPP9cVV1xxzv1ttsB07NhR0pcBuN3uVp5NZASDQZWVlSkvL09xcXGtPR1rkFv4yC485BY+sgtPW8otEAgoKyvL+Xf8XNpsgWn62MjtdrepApOUlCS32239G/RiIrfwkV14yC18ZBeetpjbN13+wUW8AADAOs0qMKWlpbruuuvUsWNHpaWl6fbbb1d1dXXImKFDhyoqKirka/LkySFjampqVFBQoKSkJKWlpWnq1Kk6depUyJh169bp2muvlcvl0tVXX61FixaFt0IAANDmNKvArF+/XoWFhdq0aZN8Pp+CwaDy8vJ09OjRkHH33HOP9u/f73zNmzfP2Xf69GkVFBTo5MmTeu+99/SHP/xBixYt0owZM5wxe/fuVUFBgW6++WZVVVWpuLhYP/vZz7R69epvuVwAANAWNOsamFWrVoU8XrRokdLS0lRZWakhQ4Y425OSkuTxeM56jLKyMn3wwQdas2aN0tPT1a9fP82ZM0fTpk3TzJkzFR8fr4ULFyonJ0dPPvmkJKlHjx7auHGjnn76aeXn5zd3jQAAoI35Vhfx1tfXS5JSU1NDti9evFgvvfSSPB6PRo0apUcffVRJSUmSpIqKCvXu3Vvp6enO+Pz8fE2ZMkW7d+9W//79VVFRodzc3JBj5ufnq7i4+JxzaWhoUENDg/M4EAhI+vLCpmAw+G2WecloWkdbWc/FQm7hI7vwkFv4yC48bSm3C11D2AWmsbFRxcXFuuGGG9SrVy9n+5133qns7GxlZmZqx44dmjZtmqqrq/X6669Lkvx+f0h5keQ89vv95x0TCAR0/PhxJSYmnjGf0tJSzZo164ztZWVlTnlqK3w+X2tPwUrkFj6yCw+5hY/swtMWcjt27NgFjQu7wBQWFmrXrl3auHFjyPZ7773X+Xvv3r2VkZGhYcOG6ZNPPtFVV10V7st9o+nTp6ukpMR53HQfeV5eXpu6jdrn82n48OFt5ja5i4Hcwkd24SG38JFdeNpSbk2foHyTsApMUVGRli9frg0bNpz3p+RJ0qBBgyRJH3/8sa666ip5PB5t2bIlZExtba0kOdfNeDweZ9tXx7jd7rOefZEkl8sll8t1xva4uDjrv5lf1xbXdDGQW/jILjzkFj6yC09byO1C59+su5CMMSoqKtIbb7yhtWvXKicn5xufU1VVJUnKyMiQJHm9Xu3cuVMHDhxwxvh8PrndbvXs2dMZU15eHnIcn88nr9fbnOkCAIA2qlkFprCwUC+99JKWLFmijh07yu/3y+/36/jx45KkTz75RHPmzFFlZaU+++wzvfnmm5owYYKGDBmiPn36SJLy8vLUs2dPjR8/Xu+//75Wr16tRx55RIWFhc4ZlMmTJ+vTTz/Vgw8+qI8++kjPPfecXn31Vd1///0RXj4AALBRswrMggULVF9fr6FDhyojI8P5Wrp0qSQpPj5ea9asUV5enrp3764HHnhAo0eP1ltvveUcIyYmRsuXL1dMTIy8Xq/uuusuTZgwQbNnz3bG5OTkaMWKFfL5fOrbt6+efPJJ/e53v+MWagAAIKmZ18AYY867PysrS+vXr//G42RnZ2vlypXnHTN06FBt3769OdMDAADtBL8LCQAAWIcCAwAArPOtfhJve3XlQyta5XVdMUbzrpd6zVythtPn/zXjX/fZ3IIWmhUAABcfZ2AAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKxDgQEAANahwAAAAOtQYAAAgHUoMAAAwDoUGAAAYB0KDAAAsA4FBgAAWIcCAwAArEOBAQAA1qHAAAAA61BgAACAdSgwAADAOhQYAABgHQoMAACwDgUGAABYhwIDAACsQ4EBAADWocAAAADrUGAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKxDgQEAANahwAAAAOtQYAAAgHUoMAAAwDoUGAAAYB0KDAAAsA4FBgAAWIcCAwAArEOBAQAA1qHAAAAA61BgAACAdSgwAADAOhQYAABgHQoMAACwDgUGAABYhwIDAACsQ4EBAADWocAAAADrUGAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKxDgQEAANahwAAAAOtQYAAAgHUoMAAAwDrNKjClpaW67rrr1LFjR6Wlpen2229XdXV1yJgTJ06osLBQnTt3VocOHTR69GjV1taGjKmpqVFBQYGSkpKUlpamqVOn6tSpUyFj1q1bp2uvvVYul0tXX321Fi1aFN4KAQBAm9OsArN+/XoVFhZq06ZN8vl8CgaDysvL09GjR50x999/v9566y299tprWr9+vfbt26c77rjD2X/69GkVFBTo5MmTeu+99/SHP/xBixYt0owZM5wxe/fuVUFBgW6++WZVVVWpuLhYP/vZz7R69eoILBkAANgutjmDV61aFfJ40aJFSktLU2VlpYYMGaL6+nr9/ve/15IlS/SjH/1IkvTiiy+qR48e2rRpkwYPHqyysjJ98MEHWrNmjdLT09WvXz/NmTNH06ZN08yZMxUfH6+FCxcqJydHTz75pCSpR48e2rhxo55++mnl5+dHaOkAAMBWzSowX1dfXy9JSk1NlSRVVlYqGAwqNzfXGdO9e3d17dpVFRUVGjx4sCoqKtS7d2+lp6c7Y/Lz8zVlyhTt3r1b/fv3V0VFRcgxmsYUFxefcy4NDQ1qaGhwHgcCAUlSMBhUMBj8Nss8gyvGRPR4F/y60Sbkz+aIdAY2aVp7e84gXGQXHnILH9mFpy3ldqFrCLvANDY2qri4WDfccIN69eolSfL7/YqPj1dKSkrI2PT0dPn9fmfMV8tL0/6mfecbEwgEdPz4cSUmJp4xn9LSUs2aNeuM7WVlZUpKSgpvkecw7/qIHq7Z5gxsbPZzVq5c2QIzsYvP52vtKViL7MJDbuEju/C0hdyOHTt2QePCLjCFhYXatWuXNm7cGO4hImr69OkqKSlxHgcCAWVlZSkvL09utzuir9VrZutci+OKNpozsFGPbotWQ2NUs567a2b7/egtGAzK5/Np+PDhiouLa+3pWIXswkNu4SO78LSl3Jo+QfkmYRWYoqIiLV++XBs2bNAVV1zhbPd4PDp58qTq6upCzsLU1tbK4/E4Y7Zs2RJyvKa7lL465ut3LtXW1srtdp/17IskuVwuuVyuM7bHxcVF/JvZcLp55SHSGhqjmj0H29/QkdAS74X2guzCQ27hI7vwtIXcLnT+zboLyRijoqIivfHGG1q7dq1ycnJC9g8YMEBxcXEqLy93tlVXV6umpkZer1eS5PV6tXPnTh04cMAZ4/P55Ha71bNnT2fMV4/RNKbpGAAAoH1r1hmYwsJCLVmyRH/84x/VsWNH55qV5ORkJSYmKjk5WZMmTVJJSYlSU1Pldrv185//XF6vV4MHD5Yk5eXlqWfPnho/frzmzZsnv9+vRx55RIWFhc4ZlMmTJ+s//uM/9OCDD+qnP/2p1q5dq1dffVUrVqyI8PIBAICNmnUGZsGCBaqvr9fQoUOVkZHhfC1dutQZ8/TTT+sf/uEfNHr0aA0ZMkQej0evv/66sz8mJkbLly9XTEyMvF6v7rrrLk2YMEGzZ892xuTk5GjFihXy+Xzq27evnnzySf3ud7/jFmoAACCpmWdgjPnm23cTEhI0f/58zZ8//5xjsrOzv/GumKFDh2r79u3NmR4AAGgn+F1IAADAOhQYAABgHQoMAACwDgUGAABYhwIDAACsQ4EBAADWocAAAADrUGAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKxDgQEAANahwAAAAOtQYAAAgHUoMAAAwDoUGAAAYB0KDAAAsA4FBgAAWIcCAwAArEOBAQAA1qHAAAAA61BgAACAdSgwAADAOhQYAABgHQoMAACwDgUGAABYhwIDAACsQ4EBAADWocAAAADrUGAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKxDgQEAANahwAAAAOtQYAAAgHUoMAAAwDoUGAAAYB0KDAAAsA4FBgAAWIcCAwAArEOBAQAA1qHAAAAA61BgAACAdSgwAADAOhQYAABgHQoMAACwDgUGAABYhwIDAACsQ4EBAADWocAAAADrUGAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKzT7AKzYcMGjRo1SpmZmYqKitKyZctC9v/kJz9RVFRUyNeIESNCxhw6dEjjxo2T2+1WSkqKJk2apCNHjoSM2bFjh2666SYlJCQoKytL8+bNa/7qAABAm9TsAnP06FH17dtX8+fPP+eYESNGaP/+/c7Xyy+/HLJ/3Lhx2r17t3w+n5YvX64NGzbo3nvvdfYHAgHl5eUpOztblZWVeuKJJzRz5kw9//zzzZ0uAABog2Kb+4SRI0dq5MiR5x3jcrnk8XjOuu/DDz/UqlWrtHXrVg0cOFCS9Nvf/la33HKLfv3rXyszM1OLFy/WyZMn9cILLyg+Pl7XXHONqqqq9NRTT4UUHQAA0D61yDUw69atU1pamrp166YpU6bo4MGDzr6KigqlpKQ45UWScnNzFR0drc2bNztjhgwZovj4eGdMfn6+qqur9cUXX7TElAEAgEWafQbmm4wYMUJ33HGHcnJy9Mknn+iXv/ylRo4cqYqKCsXExMjv9ystLS10ErGxSk1Nld/vlyT5/X7l5OSEjElPT3f2derU6YzXbWhoUENDg/M4EAhIkoLBoILBYETX6IoxET3eBb9utAn5szkinYFNmtbenjMIF9mFh9zCR3bhaUu5XegaIl5gxowZ4/y9d+/e6tOnj6666iqtW7dOw4YNi/TLOUpLSzVr1qwztpeVlSkpKSmirzXv+ogertnmDGxs9nNWrlzZAjOxi8/na+0pWIvswkNu4SO78LSF3I4dO3ZB4yJeYL7uu9/9rrp06aKPP/5Yw4YNk8fj0YEDB0LGnDp1SocOHXKum/F4PKqtrQ0Z0/T4XNfWTJ8+XSUlJc7jQCCgrKws5eXlye12R3JJ6jVzdUSPd6Fc0UZzBjbq0W3RamiMatZzd83Mb6FZXfqCwaB8Pp+GDx+uuLi41p6OVcguPOQWPrILT1vKrekTlG/S4gXmr3/9qw4ePKiMjAxJktfrVV1dnSorKzVgwABJ0tq1a9XY2KhBgwY5Yx5++GEFg0HnG+Hz+dStW7ezfnwkfXnhsMvlOmN7XFxcxL+ZDaebVx4iraExqtlzsP0NHQkt8V5oL8guPOQWPrILT1vI7ULn3+yLeI8cOaKqqipVVVVJkvbu3auqqirV1NToyJEjmjp1qjZt2qTPPvtM5eXluu2223T11VcrP//LMwA9evTQiBEjdM8992jLli169913VVRUpDFjxigzM1OSdOeddyo+Pl6TJk3S7t27tXTpUj3zzDMhZ1gAAED71ewCs23bNvXv31/9+/eXJJWUlKh///6aMWOGYmJitGPHDt166636/ve/r0mTJmnAgAF65513Qs6OLF68WN27d9ewYcN0yy236MYbbwz5GS/JyckqKyvT3r17NWDAAD3wwAOaMWMGt1ADAABJYXyENHToUBlz7rtgVq/+5utDUlNTtWTJkvOO6dOnj955553mTg8AALQD/C4kAABgHQoMAACwDgUGAABYhwIDAACsQ4EBAADWocAAAADrUGAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKxDgQEAANahwAAAAOtQYAAAgHUoMAAAwDoUGAAAYB0KDAAAsA4FBgAAWIcCAwAArEOBAQAA1qHAAAAA61BgAACAdSgwAADAOhQYAABgHQoMAACwDgUGAABYhwIDAACsQ4EBAADWocAAAADrUGAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKxDgQEAANahwAAAAOtQYAAAgHUoMAAAwDoUGAAAYB0KDAAAsA4FBgAAWIcCAwAArEOBAQAA1qHAAAAA61BgAACAdSgwAADAOhQYAABgHQoMAACwDgUGAABYhwIDAACsQ4EBAADWocAAAADrUGAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKxDgQEAANahwAAAAOs0u8Bs2LBBo0aNUmZmpqKiorRs2bKQ/cYYzZgxQxkZGUpMTFRubq727NkTMubQoUMaN26c3G63UlJSNGnSJB05ciRkzI4dO3TTTTcpISFBWVlZmjdvXvNXBwAA2qRmF5ijR4+qb9++mj9//ln3z5s3T88++6wWLlyozZs367LLLlN+fr5OnDjhjBk3bpx2794tn8+n5cuXa8OGDbr33nud/YFAQHl5ecrOzlZlZaWeeOIJzZw5U88//3wYSwQAAG1NbHOfMHLkSI0cOfKs+4wx+s1vfqNHHnlEt912myTpv//7v5Wenq5ly5ZpzJgx+vDDD7Vq1Spt3bpVAwcOlCT99re/1S233KJf//rXyszM1OLFi3Xy5Em98MILio+P1zXXXKOqqio99dRTIUUHAAC0T80uMOezd+9e+f1+5ebmOtuSk5M1aNAgVVRUaMyYMaqoqFBKSopTXiQpNzdX0dHR2rx5s3784x+roqJCQ4YMUXx8vDMmPz9f//7v/64vvvhCnTp1OuO1Gxoa1NDQ4DwOBAKSpGAwqGAwGMllyhVjInq8C37daBPyZ3NEOgObNK29PWcQLrILD7mFj+zC05Zyu9A1RLTA+P1+SVJ6enrI9vT0dGef3+9XWlpa6CRiY5WamhoyJicn54xjNO07W4EpLS3VrFmzztheVlampKSkMFd0dvOuj+jhmm3OwMZmP2flypUtMBO7+Hy+1p6CtcguPOQWPrILT1vI7dixYxc0LqIFpjVNnz5dJSUlzuNAIKCsrCzl5eXJ7XZH9LV6zVwd0eNdKFe00ZyBjXp0W7QaGqOa9dxdM/NbaFaXvmAwKJ/Pp+HDhysuLq61p2MVsgsPuYWP7MLTlnJr+gTlm0S0wHg8HklSbW2tMjIynO21tbXq16+fM+bAgQMhzzt16pQOHTrkPN/j8ai2tjZkTNPjpjFf53K55HK5ztgeFxcX8W9mw+nmlYdIa2iMavYcbH9DR0JLvBfaC7ILD7mFj+zC0xZyu9D5R/TnwOTk5Mjj8ai8vNzZFggEtHnzZnm9XkmS1+tVXV2dKisrnTFr165VY2OjBg0a5IzZsGFDyOdgPp9P3bp1O+vHRwAAoH1pdoE5cuSIqqqqVFVVJenLC3erqqpUU1OjqKgoFRcX69/+7d/05ptvaufOnZowYYIyMzN1++23S5J69OihESNG6J577tGWLVv07rvvqqioSGPGjFFmZqYk6c4771R8fLwmTZqk3bt3a+nSpXrmmWdCPiICAADtV7M/Qtq2bZtuvvlm53FTqZg4caIWLVqkBx98UEePHtW9996ruro63XjjjVq1apUSEhKc5yxevFhFRUUaNmyYoqOjNXr0aD377LPO/uTkZJWVlamwsFADBgxQly5dNGPGDG6hBgAAksIoMEOHDpUx576NNyoqSrNnz9bs2bPPOSY1NVVLliw57+v06dNH77zzTnOnBwAA2gF+FxIAALAOBQYAAFiHAgMAAKxDgQEAANahwAAAAOtQYAAAgHUoMAAAwDoUGAAAYB0KDAAAsA4FBgAAWIcCAwAArEOBAQAA1qHAAAAA61BgAACAdSgwAADAOhQYAABgHQoMAACwDgUGAABYhwIDAACsQ4EBAADWocAAAADrUGAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKxDgQEAANahwAAAAOtQYAAAgHUoMAAAwDoUGAAAYB0KDAAAsA4FBgAAWIcCAwAArEOBAQAA1qHAAAAA61BgAACAdSgwAADAOhQYAABgHQoMAACwDgUGAABYhwIDAACsQ4EBAADWocAAAADrUGAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKxDgQEAANahwAAAAOtQYAAAgHUoMAAAwDoUGAAAYB0KDAAAsA4FBgAAWCe2tSeAi+PKh1a09hTC8tncgtaeAgDgEsQZGAAAYB0KDAAAsE7EC8zMmTMVFRUV8tW9e3dn/4kTJ1RYWKjOnTurQ4cOGj16tGpra0OOUVNTo4KCAiUlJSktLU1Tp07VqVOnIj1VAABgqRa5Buaaa67RmjVr/v4isX9/mfvvv18rVqzQa6+9puTkZBUVFemOO+7Qu+++K0k6ffq0CgoK5PF49N5772n//v2aMGGC4uLi9Ktf/aolpgsAACzTIgUmNjZWHo/njO319fX6/e9/ryVLluhHP/qRJOnFF19Ujx49tGnTJg0ePFhlZWX64IMPtGbNGqWnp6tfv36aM2eOpk2bppkzZyo+Pr4lpgwAACzSIgVmz549yszMVEJCgrxer0pLS9W1a1dVVlYqGAwqNzfXGdu9e3d17dpVFRUVGjx4sCoqKtS7d2+lp6c7Y/Lz8zVlyhTt3r1b/fv3P+trNjQ0qKGhwXkcCAQkScFgUMFgMKLrc8WYiB7vgl832oT82R5E4nvXdIxIvw/aA7ILD7mFj+zC05Zyu9A1RLzADBo0SIsWLVK3bt20f/9+zZo1SzfddJN27dolv9+v+Ph4paSkhDwnPT1dfr9fkuT3+0PKS9P+pn3nUlpaqlmzZp2xvaysTElJSd9yVaHmXR/RwzXbnIGNrTuBi2jlypURO5bP54vYsdobsgsPuYWP7MLTFnI7duzYBY2LeIEZOXKk8/c+ffpo0KBBys7O1quvvqrExMRIv5xj+vTpKikpcR4HAgFlZWUpLy9Pbrc7oq/Va+bqiB7vQrmijeYMbNSj26LV0BjVKnO42HbNzP/WxwgGg/L5fBo+fLji4uIiMKv2g+zCQ27hI7vwtKXcmj5B+SYt/oPsUlJS9P3vf18ff/yxhg8frpMnT6quri7kLExtba1zzYzH49GWLVtCjtF0l9LZrqtp4nK55HK5ztgeFxcX8W9mw+nWLQ8NjVGtPoeLJZLfu5Z4L7QXZBcecgsf2YWnLeR2ofNv8Z8Dc+TIEX3yySfKyMjQgAEDFBcXp/Lycmd/dXW1ampq5PV6JUler1c7d+7UgQMHnDE+n09ut1s9e/Zs6ekCAAALRPwMzC9+8QuNGjVK2dnZ2rdvnx577DHFxMRo7NixSk5O1qRJk1RSUqLU1FS53W79/Oc/l9fr1eDBgyVJeXl56tmzp8aPH6958+bJ7/frkUceUWFh4VnPsAAAgPYn4gXmr3/9q8aOHauDBw/q8ssv14033qhNmzbp8ssvlyQ9/fTTio6O1ujRo9XQ0KD8/Hw999xzzvNjYmK0fPlyTZkyRV6vV5dddpkmTpyo2bNnR3qqAADAUhEvMK+88sp59yckJGj+/PmaP3/+OcdkZ2dH9O4TAADQtvC7kAAAgHUoMAAAwDoUGAAAYB0KDAAAsA4FBgAAWIcCAwAArEOBAQAA1qHAAAAA61BgAACAdSgwAADAOhQYAABgHQoMAACwDgUGAABYhwIDAACsQ4EBAADWocAAAADrUGAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKxDgQEAANahwAAAAOtQYAAAgHUoMAAAwDoUGAAAYB0KDAAAsA4FBgAAWIcCAwAArEOBAQAA1qHAAAAA61BgAACAdSgwAADAOhQYAABgHQoMAACwDgUGAABYhwIDAACsQ4EBAADWocAAAADrUGAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFiHAgMAAKxDgQEAANahwAAAAOtQYAAAgHUoMAAAwDoUGAAAYB0KDAAAsA4FBgAAWIcCAwAArEOBAQAA1qHAAAAA61BgAACAdSgwAADAOhQYAABgHQoMAACwTmxrTwA4nysfWvGtj+GKMZp3vdRr5mo1nI6KwKzO77O5BS3+GgDQ3l3SZ2Dmz5+vK6+8UgkJCRo0aJC2bNnS2lMCAACXgEu2wCxdulQlJSV67LHH9Kc//Ul9+/ZVfn6+Dhw40NpTAwAAreySLTBPPfWU7rnnHt19993q2bOnFi5cqKSkJL3wwgutPTUAANDKLslrYE6ePKnKykpNnz7d2RYdHa3c3FxVVFSc9TkNDQ1qaGhwHtfX10uSDh06pGAwGNH5xZ46GtHjXfDrNhodO9ao2GC0Tje2/LUcbcXFzu3qX7za4q8RaZunDzvr9mAwqGPHjungwYOKi4u7yLOyF7mFj+zC05ZyO3z4sCTJGHPecZdkgfm///s/nT59Wunp6SHb09PT9dFHH531OaWlpZo1a9YZ23Nyclpkjq3lztaegKXI7fy6PNnaMwCAUIcPH1ZycvI591+SBSYc06dPV0lJifO4sbFRhw4dUufOnRUV1TbOVgQCAWVlZenzzz+X2+1u7elYg9zCR3bhIbfwkV142lJuxhgdPnxYmZmZ5x13SRaYLl26KCYmRrW1tSHba2tr5fF4zvocl8sll8sVsi0lJaWlptiq3G639W/Q1kBu4SO78JBb+MguPG0lt/OdeWlySV7EGx8frwEDBqi8vNzZ1tjYqPLycnm93lacGQAAuBRckmdgJKmkpEQTJ07UwIEDdf311+s3v/mNjh49qrvvvru1pwYAAFrZJVtg/vmf/1n/+7//qxkzZsjv96tfv35atWrVGRf2ticul0uPPfbYGR+V4fzILXxkFx5yCx/Zhac95hZlvuk+JQAAgEvMJXkNDAAAwPlQYAAAgHUoMAAAwDoUGAAAYB0KTCsqLS3Vddddp44dOyotLU233367qqurQ8acOHFChYWF6ty5szp06KDRo0ef8QP+ampqVFBQoKSkJKWlpWnq1Kk6derUxVxKq5s7d66ioqJUXFzsbCO7s/vb3/6mu+66S507d1ZiYqJ69+6tbdu2OfuNMZoxY4YyMjKUmJio3Nxc7dmzJ+QYhw4d0rhx4+R2u5WSkqJJkybpyJEjF3spF9Xp06f16KOPKicnR4mJibrqqqs0Z86ckN/XQnZf2rBhg0aNGqXMzExFRUVp2bJlIfsjldOOHTt00003KSEhQVlZWZo3b15LL61FnS+3YDCoadOmqXfv3rrsssuUmZmpCRMmaN++fSHHaFe5GbSa/Px88+KLL5pdu3aZqqoqc8stt5iuXbuaI0eOOGMmT55ssrKyTHl5udm2bZsZPHiw+cEPfuDsP3XqlOnVq5fJzc0127dvNytXrjRdunQx06dPb40ltYotW7aYK6+80vTp08fcd999znayO9OhQ4dMdna2+clPfmI2b95sPv30U7N69Wrz8ccfO2Pmzp1rkpOTzbJly8z7779vbr31VpOTk2OOHz/ujBkxYoTp27ev2bRpk3nnnXfM1VdfbcaOHdsaS7poHn/8cdO5c2ezfPlys3fvXvPaa6+ZDh06mGeeecYZQ3ZfWrlypXn44YfN66+/biSZN954I2R/JHKqr6836enpZty4cWbXrl3m5ZdfNomJieY///M/L9YyI+58udXV1Znc3FyzdOlS89FHH5mKigpz/fXXmwEDBoQcoz3lRoG5hBw4cMBIMuvXrzfGfPmGjYuLM6+99poz5sMPPzSSTEVFhTHmyzd8dHS08fv9zpgFCxYYt9ttGhoaLu4CWsHhw4fN9773PePz+cwPf/hDp8CQ3dlNmzbN3Hjjjefc39jYaDwej3niiSecbXV1dcblcpmXX37ZGGPMBx98YCSZrVu3OmP+53/+x0RFRZm//e1vLTf5VlZQUGB++tOfhmy74447zLhx44wxZHcuX/+HOFI5Pffcc6ZTp04h/61OmzbNdOvWrYVXdHGcrfh93ZYtW4wk85e//MUY0/5y4yOkS0h9fb0kKTU1VZJUWVmpYDCo3NxcZ0z37t3VtWtXVVRUSJIqKirUu3fvkB/wl5+fr0AgoN27d1/E2beOwsJCFRQUhGQkkd25vPnmmxo4cKD+8R//UWlpaerfv7/+67/+y9m/d+9e+f3+kNySk5M1aNCgkNxSUlI0cOBAZ0xubq6io6O1efPmi7eYi+wHP/iBysvL9ec//1mS9P7772vjxo0aOXKkJLK7UJHKqaKiQkOGDFF8fLwzJj8/X9XV1friiy8u0mpaV319vaKiopzf+9fecrtkfxJve9PY2Kji4mLdcMMN6tWrlyTJ7/crPj7+jF9KmZ6eLr/f74z5+k8nbnrcNKateuWVV/SnP/1JW7duPWMf2Z3dp59+qgULFqikpES//OUvtXXrVv3rv/6r4uPjNXHiRGfdZ8vlq7mlpaWF7I+NjVVqamqbzU2SHnroIQUCAXXv3l0xMTE6ffq0Hn/8cY0bN06SyO4CRSonv9+vnJycM47RtK9Tp04tMv9LxYkTJzRt2jSNHTvW+eWN7S03CswlorCwULt27dLGjRtbeypW+Pzzz3XffffJ5/MpISGhtadjjcbGRg0cOFC/+tWvJEn9+/fXrl27tHDhQk2cOLGVZ3dpe/XVV7V48WItWbJE11xzjaqqqlRcXKzMzEyyw0UVDAb1T//0TzLGaMGCBa09nVbDR0iXgKKiIi1fvlxvv/22rrjiCme7x+PRyZMnVVdXFzK+trZWHo/HGfP1O2uaHjeNaYsqKyt14MABXXvttYqNjVVsbKzWr1+vZ599VrGxsUpPTye7s8jIyFDPnj1DtvXo0UM1NTWS/r7us+Xy1dwOHDgQsv/UqVM6dOhQm81NkqZOnaqHHnpIY8aMUe/evTV+/Hjdf//9Ki0tlUR2FypSObXH/36lv5eXv/zlL/L5fM7ZF6n95UaBaUXGGBUVFemNN97Q2rVrzzitN2DAAMXFxam8vNzZVl1drZqaGnm9XkmS1+vVzp07Q960TW/qr/9D1ZYMGzZMO3fuVFVVlfM1cOBAjRs3zvk72Z3phhtuOONW/T//+c/Kzs6WJOXk5Mjj8YTkFggEtHnz5pDc6urqVFlZ6YxZu3atGhsbNWjQoIuwitZx7NgxRUeH/i8zJiZGjY2NksjuQkUqJ6/Xqw0bNigYDDpjfD6funXrZtXHIM3RVF727NmjNWvWqHPnziH7211urX0VcXs2ZcoUk5ycbNatW2f279/vfB07dswZM3nyZNO1a1ezdu1as23bNuP1eo3X63X2N90KnJeXZ6qqqsyqVavM5Zdf3qZvBT6Xr96FZAzZnc2WLVtMbGysefzxx82ePXvM4sWLTVJSknnppZecMXPnzjUpKSnmj3/8o9mxY4e57bbbznqLa//+/c3mzZvNxo0bzfe+9702dyvw102cONF85zvfcW6jfv31102XLl3Mgw8+6Iwhuy8dPnzYbN++3Wzfvt1IMk899ZTZvn27c7dMJHKqq6sz6enpZvz48WbXrl3mlVdeMUlJSVbeDtzkfLmdPHnS3HrrreaKK64wVVVVIf9mfPWOovaUGwWmFUk669eLL77ojDl+/Lj5l3/5F9OpUyeTlJRkfvzjH5v9+/eHHOezzz4zI0eONImJiaZLly7mgQceMMFg8CKvpvV9vcCQ3dm99dZbplevXsblcpnu3bub559/PmR/Y2OjefTRR016erpxuVxm2LBhprq6OmTMwYMHzdixY02HDh2M2+02d999tzl8+PDFXMZFFwgEzH333We6du1qEhISzHe/+13z8MMPh/zjQXZfevvtt8/6/7aJEycaYyKX0/vvv29uvPFG43K5zHe+8x0zd+7ci7XEFnG+3Pbu3XvOfzPefvtt5xjtKbcoY77yYyQBAAAswDUwAADAOhQYAABgHQoMAACwDgUGAABYhwIDAACsQ4EBAADWocAAAADrUGAAAIB1KDAAAMA6FBgAAGAdCgwAALAOBQYAAFjn/wGYoDumK8mYrAAAAABJRU5ErkJggg==\n"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"class MathDataset(Dataset):\n    def __init__(self, prompts, targets):\n        self.prompts = prompts  # 输入：题目（字符串数组）\n        self.targets = targets  # 标签：对应分类标签（int数组）\n\n    def __getitem__(self, idx):\n        # 支持通过索引访问第 idx 条样本\n        return self.prompts[idx], self.targets[idx]\n\n    def __len__(self):\n        # 数据集长度（总样本数）\n        return len(self.targets)\n        \n# Split the test set into 4 parts\n# 获取测试集总长度\nlength = len(test)\n\n# 按 4 份平均划分（每份大小）\nsplit_size = length // 4\n\n# Create dataloaders for each GPU\ntest_datasets = []\ntest_dataloaders = []\n\nfor i in range(4):\n    start_idx = i * split_size\n    end_idx = (i + 1) * split_size if i < 3 else length  # 最后一块可能包含余数\n\n    # 构造数据集（MathDataset 是我们上面定义的类）\n    dataset = MathDataset(\n        prompts=test['problem'].iloc[start_idx:end_idx].to_numpy(),\n        targets=test['target'].iloc[start_idx:end_idx].to_numpy()\n    )\n    \n    # 构造 DataLoader，batch_size=1（逐条推理），不打乱顺序\n    dataloader = DataLoader(\n        dataset=dataset,\n        batch_size=1,\n        shuffle=False,\n        drop_last=False\n    )\n    \n    # 存入列表中备用\n    test_dataloaders.append(dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:30:25.734072Z","iopub.execute_input":"2025-05-12T08:30:25.734305Z","iopub.status.idle":"2025-05-12T08:30:25.740622Z","shell.execute_reply.started":"2025-05-12T08:30:25.734283Z","shell.execute_reply":"2025-05-12T08:30:25.740059Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def get_preds(model, tokenizer, test_dataloader, device, results):\n    # 初始化预测结果容器\n    y_pred = torch.tensor([])  # 存储预测 logits\n    y_true = torch.tensor([])  # （未使用，可删）\n\n    with torch.no_grad():  # 禁用梯度计算（节省显存）\n        model.eval()  # 切换到评估模式\n\n        # 遍历测试集 DataLoader\n        for batch_idx, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n            batch_prompts, batch_targets = batch  # 解包：输入和目标\n\n            # 编码文本，转为张量，移动到指定设备\n            encodings = tokenizer(batch_prompts, return_tensors='pt', padding=True, truncation=True, max_length=400).to(device)\n\n            batch_targets = batch_targets.long().to(device)  # 转换目标为 long 类型（未使用）\n\n            # 启用自动混合精度以加速推理\n            with autocast(device_type=device):\n                logits = model(encodings)  # 得到模型输出（logits）\n\n                y_pred = torch.cat([y_pred, logits.cpu()])  # 将当前 batch 结果拼接进总结果\n\n    # 将当前设备上的预测结果存入共享结果字典\n    results[device] = y_pred\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:30:27.845015Z","iopub.execute_input":"2025-05-12T08:30:27.845246Z","iopub.status.idle":"2025-05-12T08:30:27.849812Z","shell.execute_reply.started":"2025-05-12T08:30:27.845231Z","shell.execute_reply":"2025-05-12T08:30:27.849316Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, base_model_path, trained_backbone_path, load_in_device):\n        super(Net, self).__init__()\n\n        # 加载模型配置（例如 hidden_size）\n        self.config = AutoConfig.from_pretrained(base_model_path)\n\n        # 配置 bitsandbytes 的 4-bit 量化加载参数\n        bnb_config = BitsAndBytesConfig(\n            load_in_4bit=True,                      # 启用 4-bit 权重量化\n            bnb_4bit_use_double_quant=True,         # 启用双重量化\n            bnb_4bit_quant_type=\"nf4\",              # 使用 nf4 量化类型\n            bnb_4bit_compute_dtype=torch.float16    # 推理使用 float16 精度\n        )\n\n        # 加载训练好的 backbone 模型（含 LoRA 权重），支持特征抽取任务\n        self.backbone = AutoPeftModelForFeatureExtraction.from_pretrained(\n            trained_backbone_path,                  # 已微调的模型路径\n            use_cache=False,                        # 不启用缓存（节省显存）\n            torch_dtype=torch.float16,              # 模型加载为 fp16\n            quantization_config=bnb_config,         # 使用 4-bit 配置\n            device_map=load_in_device               # 指定加载到的 GPU 设备\n        )\n\n        # 定义分类头（8 类），输入维度为模型的 hidden_size\n        self.head = nn.Linear(self.config.hidden_size, 8, bias=False)\n\n    def forward(self, x):\n        # 获取最后一个 token 的隐藏状态向量（作为句子表示）\n        x = self.backbone(**x).last_hidden_state[:, -1, :]\n\n        # 送入分类头，输出 8 维 logits\n        return self.head(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:30:29.547637Z","iopub.execute_input":"2025-05-12T08:30:29.548304Z","iopub.status.idle":"2025-05-12T08:30:29.552984Z","shell.execute_reply.started":"2025-05-12T08:30:29.548282Z","shell.execute_reply":"2025-05-12T08:30:29.552452Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# 14b-qwen3-fold-1\ntrained_backbone_path = '/kaggle/input/best-fold-0-backbone'\ntrained_head_path = '/kaggle/input/best-fold-0-head/head_fold_0_best.pt'\n\nmodel_1 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:0')\n\nmodel_2 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:1')\n\nmodel_3 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:2')\n\nmodel_4 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:3')\n\nmodel_1.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_2.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_3.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_4.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\n\nmodel_1.head.to('cuda:0')\nmodel_2.head.to('cuda:1')\nmodel_3.head.to('cuda:2')\nmodel_4.head.to('cuda:3')\n\nresults = {}\n\nt0 = Thread(target=get_preds, args=(model_1, tokenizer, test_dataloaders[0], 'cuda:0', results))\nt1 = Thread(target=get_preds, args=(model_2, tokenizer, test_dataloaders[1], 'cuda:1', results))\nt2 = Thread(target=get_preds, args=(model_3, tokenizer, test_dataloaders[2], 'cuda:2', results))\nt3 = Thread(target=get_preds, args=(model_4, tokenizer, test_dataloaders[3], 'cuda:3', results))\n\nt0.start()\nt1.start()\nt2.start()\nt3.start()\n\nt0.join()\nt1.join()\nt2.join()\nt3.join()\n\nlogits_fold_1 = torch.cat([results['cuda:0'], results['cuda:1'], results['cuda:2'], results['cuda:3']])\npred_probs_fold_1 = F.softmax(logits_fold_1, dim=-1)\n\ndel model_1, model_2, model_3, model_4\nclean_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:30:31.648051Z","iopub.execute_input":"2025-05-12T08:30:31.648650Z","iopub.status.idle":"2025-05-12T08:45:47.615358Z","shell.execute_reply.started":"2025-05-12T08:30:31.648629Z","shell.execute_reply":"2025-05-12T08:45:47.614753Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"854f6185d53346bbbe47ba12d1884412"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3be64ca0c24462cbe0376448510636d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34478274378b4b158981d792e0141ded"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdb1d8dd0fd542b79a8fb835b58649cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d731792f00e461bb2d7ea0ebdf8dbe1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27ac3d12771e43d3885585fc1caac97e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd7c93f15642495592707fb3eef68c1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93697e02eeab460eb51f5267234bf901"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# 14b-qwen3 fold-2\ntrained_backbone_path = '/kaggle/input/best-fold-1-backbone'\ntrained_head_path = '/kaggle/input/best-fold-1-head/head_fold_1_best.pt'\n\nmodel_1 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:0')\n\nmodel_2 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:1')\n\nmodel_3 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:2')\n\nmodel_4 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:3')\n\nmodel_1.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_2.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_3.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_4.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\n\nmodel_1.head.to('cuda:0')\nmodel_2.head.to('cuda:1')\nmodel_3.head.to('cuda:2')\nmodel_4.head.to('cuda:3')\n\nresults = {}\n\nt0 = Thread(target=get_preds, args=(model_1, tokenizer, test_dataloaders[0], 'cuda:0', results))\nt1 = Thread(target=get_preds, args=(model_2, tokenizer, test_dataloaders[1], 'cuda:1', results))\nt2 = Thread(target=get_preds, args=(model_3, tokenizer, test_dataloaders[2], 'cuda:2', results))\nt3 = Thread(target=get_preds, args=(model_4, tokenizer, test_dataloaders[3], 'cuda:3', results))\n\nt0.start()\nt1.start()\nt2.start()\nt3.start()\n\nt0.join()\nt1.join()\nt2.join()\nt3.join()\n\nlogits_fold_2 = torch.cat([results['cuda:0'], results['cuda:1'], results['cuda:2'], results['cuda:3']])\npred_probs_fold_2 = F.softmax(logits_fold_2, dim=-1)\n\ndel model_1, model_2, model_3, model_4\nclean_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:46:12.441258Z","iopub.execute_input":"2025-05-12T08:46:12.442020Z","iopub.status.idle":"2025-05-12T08:57:39.220402Z","shell.execute_reply.started":"2025-05-12T08:46:12.441993Z","shell.execute_reply":"2025-05-12T08:57:39.219776Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b4a0dd63fee4dea980fe3394c014ad4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e03d46a012874176939d73912d334655"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"882b40963dec4d209aede5529f83f380"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a8e23927a494857ad0ac2ea6c59a942"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e87f4a2550ae4b0ba1da0d5aafe343bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02207fcc03514610b6321e8ad6735ba0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9f1790a81a14b93adac8bb3d8b69808"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36ca2bfad9564b169bd3fb77fcacf15b"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# 14b-qwen 3 fold-3\ntrained_backbone_path = '/kaggle/input/best-fold-2-backbone'\ntrained_head_path = '/kaggle/input/best-fold-2-head/head_fold_2_best.pt'\n\nmodel_1 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:0')\n\nmodel_2 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:1')\n\nmodel_3 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:2')\n\nmodel_4 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:3')\n\nmodel_1.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_2.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_3.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_4.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\n\nmodel_1.head.to('cuda:0')\nmodel_2.head.to('cuda:1')\nmodel_3.head.to('cuda:2')\nmodel_4.head.to('cuda:3')\n\nresults = {}\n\nt0 = Thread(target=get_preds, args=(model_1, tokenizer, test_dataloaders[0], 'cuda:0', results))\nt1 = Thread(target=get_preds, args=(model_2, tokenizer, test_dataloaders[1], 'cuda:1', results))\nt2 = Thread(target=get_preds, args=(model_3, tokenizer, test_dataloaders[2], 'cuda:2', results))\nt3 = Thread(target=get_preds, args=(model_4, tokenizer, test_dataloaders[3], 'cuda:3', results))\n\nt0.start()\nt1.start()\nt2.start()\nt3.start()\n\nt0.join()\nt1.join()\nt2.join()\nt3.join()\n\nlogits_fold_3 = torch.cat([results['cuda:0'], results['cuda:1'], results['cuda:2'], results['cuda:3']])\npred_probs_fold_3 = F.softmax(logits_fold_3, dim=-1)\n\ndel model_1, model_2, model_3, model_4\nclean_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:58:21.560294Z","iopub.execute_input":"2025-05-12T08:58:21.560946Z","iopub.status.idle":"2025-05-12T09:09:48.944458Z","shell.execute_reply.started":"2025-05-12T08:58:21.560924Z","shell.execute_reply":"2025-05-12T09:09:48.943856Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f94089055efd4c6a8ab93ef482fd3a7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dbcd810c32547ddae11f2b1eccfd947"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e48db20558544773b3176feef4c490a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be74ac3d5844fcb85bda6192262fb03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecaea839de464a2d93aaecaf7bb7c06f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d52b0f7ed074c9c839c08e828aec4e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa31b351b5264f0dbb53e1df05cdfec1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a4d528654c74b5ca2fa42755fbd33cf"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"pred_probs_qwen3_14b = (pred_probs_fold_1 + pred_probs_fold_2 + pred_probs_fold_3) / 3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T09:10:23.238383Z","iopub.execute_input":"2025-05-12T09:10:23.239039Z","iopub.status.idle":"2025-05-12T09:10:23.242269Z","shell.execute_reply.started":"2025-05-12T09:10:23.239018Z","shell.execute_reply":"2025-05-12T09:10:23.241655Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df_1 = pd.DataFrame(pred_probs_fold_1.argmax(-1).tolist(), columns=['3fold_1'])\ndf_1['3fold_2'] = pred_probs_fold_2.argmax(-1).tolist()\ndf_1['3fold_3'] = pred_probs_fold_3.argmax(-1).tolist()\ndf_1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T09:10:24.781481Z","iopub.execute_input":"2025-05-12T09:10:24.782126Z","iopub.status.idle":"2025-05-12T09:10:24.799387Z","shell.execute_reply.started":"2025-05-12T09:10:24.782104Z","shell.execute_reply":"2025-05-12T09:10:24.798913Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"      3fold_1  3fold_2  3fold_3\n0           0        0        0\n1           4        4        4\n2           0        2        0\n3           4        4        4\n4           4        4        4\n...       ...      ...      ...\n3039        4        4        4\n3040        1        1        1\n3041        1        1        1\n3042        4        4        4\n3043        5        5        5\n\n[3044 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>3fold_1</th>\n      <th>3fold_2</th>\n      <th>3fold_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3039</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3040</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3041</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3042</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3043</th>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>3044 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"model_path = '/kaggle/input/qwen2.5/transformers/14b/1'\n\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\ntokenizer.padding_side = 'left'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T09:10:33.200188Z","iopub.execute_input":"2025-05-12T09:10:33.200830Z","iopub.status.idle":"2025-05-12T09:10:33.714602Z","shell.execute_reply.started":"2025-05-12T09:10:33.200805Z","shell.execute_reply":"2025-05-12T09:10:33.714046Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# 14b-qwen2.5 fold-1\ntrained_backbone_path = '/kaggle/input/qwen2-5-best-fold-0-backbone'\ntrained_head_path = '/kaggle/input/qwen2-5-best-fold-0-head/head_fold_0_best.pt'\n\nmodel_1 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:0')\n\nmodel_2 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:1')\n\nmodel_3 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:2')\n\nmodel_4 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:3')\n\nmodel_1.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_2.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_3.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_4.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\n\nmodel_1.head.to('cuda:0')\nmodel_2.head.to('cuda:1')\nmodel_3.head.to('cuda:2')\nmodel_4.head.to('cuda:3')\n\nresults = {}\n\nt0 = Thread(target=get_preds, args=(model_1, tokenizer, test_dataloaders[0], 'cuda:0', results))\nt1 = Thread(target=get_preds, args=(model_2, tokenizer, test_dataloaders[1], 'cuda:1', results))\nt2 = Thread(target=get_preds, args=(model_3, tokenizer, test_dataloaders[2], 'cuda:2', results))\nt3 = Thread(target=get_preds, args=(model_4, tokenizer, test_dataloaders[3], 'cuda:3', results))\n\nt0.start()\nt1.start()\nt2.start()\nt3.start()\n\nt0.join()\nt1.join()\nt2.join()\nt3.join()\n\nlogits_fold_1 = torch.cat([results['cuda:0'], results['cuda:1'], results['cuda:2'], results['cuda:3']])\npred_probs_fold_1 = F.softmax(logits_fold_1, dim=-1)\n\ndel model_1, model_2, model_3, model_4\nclean_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T09:10:35.165102Z","iopub.execute_input":"2025-05-12T09:10:35.165704Z","iopub.status.idle":"2025-05-12T09:28:43.508236Z","shell.execute_reply.started":"2025-05-12T09:10:35.165684Z","shell.execute_reply":"2025-05-12T09:28:43.507629Z"}},"outputs":[{"name":"stderr","text":"Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1c25713546d44588ce8d1212420cb84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c81925984744b7ea0e75f56baefb8e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1073308ad33466b9273622d66b381a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeadf365d09144dc8ccd5dc796901cbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b9898d73bdf463cad8a184662e91efc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1520e716a8c4b29a78be374f1da1b04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0337ef95b2a4b209707fbd49a655fc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"226c37a79ccc42179f45e0b0371bfb91"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# 14b-qwen2.5 fold-2\ntrained_backbone_path = '/kaggle/input/qwen2-5-best-fold-1-backbone'\ntrained_head_path = '/kaggle/input/qwen2-5-best-fold-1-head/head_fold_1_best.pt'\n\nmodel_1 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:0')\n\nmodel_2 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:1')\n\nmodel_3 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:2')\n\nmodel_4 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:3')\n\nmodel_1.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_2.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_3.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_4.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\n\nmodel_1.head.to('cuda:0')\nmodel_2.head.to('cuda:1')\nmodel_3.head.to('cuda:2')\nmodel_4.head.to('cuda:3')\n\nresults = {}\n\nt0 = Thread(target=get_preds, args=(model_1, tokenizer, test_dataloaders[0], 'cuda:0', results))\nt1 = Thread(target=get_preds, args=(model_2, tokenizer, test_dataloaders[1], 'cuda:1', results))\nt2 = Thread(target=get_preds, args=(model_3, tokenizer, test_dataloaders[2], 'cuda:2', results))\nt3 = Thread(target=get_preds, args=(model_4, tokenizer, test_dataloaders[3], 'cuda:3', results))\n\nt0.start()\nt1.start()\nt2.start()\nt3.start()\n\nt0.join()\nt1.join()\nt2.join()\nt3.join()\n\nlogits_fold_2 = torch.cat([results['cuda:0'], results['cuda:1'], results['cuda:2'], results['cuda:3']])\npred_probs_fold_2 = F.softmax(logits_fold_2, dim=-1)\n\ndel model_1, model_2, model_3, model_4\nclean_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T09:29:27.045689Z","iopub.execute_input":"2025-05-12T09:29:27.046359Z","iopub.status.idle":"2025-05-12T09:42:05.797434Z","shell.execute_reply.started":"2025-05-12T09:29:27.046339Z","shell.execute_reply":"2025-05-12T09:42:05.796836Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c0d159656104b4bb53d2140eb114a85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"026da8da749343428e03df34e0d7a69d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8f9b0ddd994815807f6cac5d9b52dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ad6b578b3164e1a8913b2e1fb757f56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"381dd853f1bb4063978a829211a5819d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be628bee31494ec8bc9e2d8c717406d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2f664670a7248f6ae62bf547089db61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf82d06dad304e6abc285b89be150120"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# 14b-qwen2.5 fold-3\ntrained_backbone_path = '/kaggle/input/qwen2-5-best-fold-2-backbone'\ntrained_head_path = '/kaggle/input/qwen2-5-best-fold-2-head/head_fold_2_best.pt'\n\nmodel_1 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:0')\n\nmodel_2 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:1')\n\nmodel_3 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:2')\n\nmodel_4 = Net(base_model_path=model_path, \n              trained_backbone_path=trained_backbone_path,\n              load_in_device='cuda:3')\n\nmodel_1.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_2.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_3.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\nmodel_4.head.load_state_dict(torch.load(trained_head_path, weights_only=True))\n\nmodel_1.head.to('cuda:0')\nmodel_2.head.to('cuda:1')\nmodel_3.head.to('cuda:2')\nmodel_4.head.to('cuda:3')\n\nresults = {}\n\nt0 = Thread(target=get_preds, args=(model_1, tokenizer, test_dataloaders[0], 'cuda:0', results))\nt1 = Thread(target=get_preds, args=(model_2, tokenizer, test_dataloaders[1], 'cuda:1', results))\nt2 = Thread(target=get_preds, args=(model_3, tokenizer, test_dataloaders[2], 'cuda:2', results))\nt3 = Thread(target=get_preds, args=(model_4, tokenizer, test_dataloaders[3], 'cuda:3', results))\n\nt0.start()\nt1.start()\nt2.start()\nt3.start()\n\nt0.join()\nt1.join()\nt2.join()\nt3.join()\n\nlogits_fold_3 = torch.cat([results['cuda:0'], results['cuda:1'], results['cuda:2'], results['cuda:3']])\npred_probs_fold_3 = F.softmax(logits_fold_3, dim=-1)\n\ndel model_1, model_2, model_3, model_4\nclean_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T09:42:26.546216Z","iopub.execute_input":"2025-05-12T09:42:26.546843Z","iopub.status.idle":"2025-05-12T09:54:49.959531Z","shell.execute_reply.started":"2025-05-12T09:42:26.546822Z","shell.execute_reply":"2025-05-12T09:54:49.958946Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ac5614f306845c9b03d08d4ad9cf8db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"663bfdcb29614bb19f71598701d8252c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"499edcc507a44bd8afee5e8b0b23dbbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5c6277b61fe4d61a63b688a4815a3c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ebd0946b2e34ad6aa9d5dbe97befa43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"756b93904b45488fb8bb6edd2a1902c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2faea28b574a4b279382904d87686e75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/761 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"079aaf9413bc43148229a6ee4d186974"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"pred_probs_qwen25_14 = (pred_probs_fold_1 + pred_probs_fold_2 + pred_probs_fold_3) / 3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T09:55:02.638422Z","iopub.execute_input":"2025-05-12T09:55:02.639050Z","iopub.status.idle":"2025-05-12T09:55:02.642030Z","shell.execute_reply.started":"2025-05-12T09:55:02.639029Z","shell.execute_reply":"2025-05-12T09:55:02.641490Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"df_2 = pd.DataFrame(pred_probs_fold_1.argmax(-1).tolist(), columns=['25fold_1'])\ndf_2['25fold_2'] = pred_probs_fold_2.argmax(-1).tolist()\ndf_2['25fold_3'] = pred_probs_fold_3.argmax(-1).tolist()\ndf_2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T09:55:04.206198Z","iopub.execute_input":"2025-05-12T09:55:04.206739Z","iopub.status.idle":"2025-05-12T09:55:04.218048Z","shell.execute_reply.started":"2025-05-12T09:55:04.206720Z","shell.execute_reply":"2025-05-12T09:55:04.217530Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"      25fold_1  25fold_2  25fold_3\n0            0         0         0\n1            4         4         4\n2            0         2         0\n3            4         0         4\n4            4         4         4\n...        ...       ...       ...\n3039         4         4         4\n3040         1         1         1\n3041         1         1         1\n3042         4         4         4\n3043         5         5         5\n\n[3044 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>25fold_1</th>\n      <th>25fold_2</th>\n      <th>25fold_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3039</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3040</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3041</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3042</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3043</th>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>3044 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"ensembled_pred_probs = pred_probs_qwen3_14b*0.6 + 0.4*pred_probs_qwen25_14","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T09:55:06.330746Z","iopub.execute_input":"2025-05-12T09:55:06.331055Z","iopub.status.idle":"2025-05-12T09:55:06.334131Z","shell.execute_reply.started":"2025-05-12T09:55:06.331035Z","shell.execute_reply":"2025-05-12T09:55:06.333589Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"df = pd.concat([df_1, df_2], axis=1).values\n\nfrom scipy import stats\nmode_result = stats.mode(df, axis=1, keepdims=False)\ny_pred = mode_result.mode.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T09:55:08.347137Z","iopub.execute_input":"2025-05-12T09:55:08.347379Z","iopub.status.idle":"2025-05-12T09:55:08.475387Z","shell.execute_reply.started":"2025-05-12T09:55:08.347364Z","shell.execute_reply":"2025-05-12T09:55:08.474842Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"sub = test[['id']].copy()\nsub['label'] = ensembled_pred_probs.argmax(dim=-1).tolist()\nsub.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T09:55:09.832707Z","iopub.execute_input":"2025-05-12T09:55:09.833322Z","iopub.status.idle":"2025-05-12T09:55:09.854440Z","shell.execute_reply.started":"2025-05-12T09:55:09.833302Z","shell.execute_reply":"2025-05-12T09:55:09.853929Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}