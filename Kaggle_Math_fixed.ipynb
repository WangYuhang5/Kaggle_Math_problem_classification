{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9xw1xy3g7N6",
    "outputId": "a0aad587-3a15-42fc-a59a-b25be58a2bf2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import AutoTokenizer, AutoModel, get_scheduler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.auto import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxxybtzEhHgv",
    "outputId": "001b4424-0b76-43a0-c9dc-e400912f5978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Question', 'label'], dtype='object')\n",
      "                                            Question  label\n",
      "0  A solitaire game is played as follows.  Six di...      3\n",
      "1  2. The school table tennis championship was he...      5\n",
      "2  Given that $x, y,$ and $z$ are real numbers th...      0\n",
      "3  $25 \\cdot 22$ Given three distinct points $P\\l...      1\n",
      "4  I am thinking of a five-digit number composed ...      5\n"
     ]
    }
   ],
   "source": [
    "# ========== Step 1. åŠ è½½æ•°æ® ==========\n",
    "df_train = pd.read_csv(\"/content/train.csv\")\n",
    "df_test = pd.read_csv(\"/content/test.csv\")\n",
    "print(df_train.columns)\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279,
     "referenced_widgets": [
      "49a4949bd0974c0190deb7ccac382268",
      "7802172fd4ce40058e2e16e4744cf94c",
      "1c4e628407124750acb58092dd2c7363",
      "3c75323a7cc0472ead3f12602e09731b",
      "04de2fe9cef443259a361103465c6f1a",
      "03074ec5e44840d0a6b8d4ef72216a19",
      "2e4536f5f93e45e28ace679f09a734bb",
      "d93963ada1844e5497904b0ce92bb5e5",
      "c6a7da466641454d90944921860a0356",
      "ea75e771d0b84b7892dcd07950cbb029",
      "0ab3f62cf13046d5acf288046e6b5fae",
      "541d354512d34c3abdc4eb3c980f9472",
      "7fac26bc4ee34738a50f6f1c4e103fde",
      "ce58a23703db44d3899acf5bdfa4940f",
      "242ff721d9994465aa883f5c765b118e",
      "af9d1b61199b45169e227f8c7c4e207a",
      "6c55478b480346c0be9ea905467ab1b7",
      "bb668f3809374f7580f40cc7a624ad89",
      "e2a61b8fa9514f08accb0ea2e8833b4c",
      "6a6f006822544cdfbf849e55e85f2c2d",
      "0f43c68ac0624af09b8f7db00bd5b7d2",
      "1089828703b84184bcdd6d7265e5d5f4",
      "55f518092e824ed6a48235a3e91b278f",
      "082de8607cbe4464923fed6bdd7cbdb4",
      "04e75f23f8a145e98c4f654e5d899535",
      "8074414573084a87a77a78295f18fb65",
      "2242206c6338433180316c7e6f5a565c",
      "842d0bc5c6324c389effe2f194283ee2",
      "4796488adbc748339dd52d4d55ee4910",
      "c753274137bd4b43965480bfcdbd3d60",
      "3420fd573d794eb3a46bdde136035057",
      "a0bed589152d4088b3b61b9ec32de5a0",
      "7c384304a5804b6b97f3c291e45788e7",
      "1d1595ec16b4440080b124c54954bd29",
      "6cabcb7f47a446a399b5030336fac395",
      "c1d77718d572408b9fd930df716fffdc",
      "f2b3d6b0ddf8478b8988c39812b5b5dd",
      "21beebe54b4c427c828c782c27e8d339",
      "06bddbcc96af4386a2c091978893833f",
      "3eb697dee967443997c7c16965c4be97",
      "5d36c64938844e6aa9e7e1bd769f8a5e",
      "6fbc39e44f2042218b7cd243703de2ce",
      "eb76444ef5ad43b4abd00931b8303389",
      "1a6a473ec2394de8938c9f975d318ad1",
      "bc109d7338be40c0b8d3c7fd9e88db3e",
      "0dd8ae22daaf43e482c674e738e7884c",
      "4df39c5fa36940f4b61d0fd4c8bca124",
      "53bab964d61e4a2e8bd65713139da77d",
      "af5d229f82bd4377b4f64dd81aae5bbb",
      "800282069ac346c98f5e46ba4784f85d",
      "e5fa9b7d5dbb472a81b7a837ae04a4dd",
      "6b79874bb1814871be3e1c9ab2a46ddc",
      "1d580199936a484f98f0c5300bc29efa",
      "b1957981c78348a4a337d21ef62125ad",
      "ab0e73fe2dea4be38fc359f37e74ad29",
      "559af10a0c654a1695a7bf1f3eeedf92",
      "8d01485a0c964e0e9acb75d5e0beb040",
      "255c6f94e3a84f5d8cb196dbce77e0df",
      "72bb2ce4a90b417caff9c9a89d405af2",
      "b50389ff1d6b41c78f7a4935a4d752e2",
      "499ab376d34d4b1c98d1f50269bec678",
      "9f37d42888fc4d88a56b7bd5b4109ea5",
      "40766604156f4412abb129575df5e3e0",
      "823f3772c7c74227b682b2412895769f",
      "5f92c70b08df474faf12c894010fdbd1",
      "6c75ae9573534802bfd485dda39e6eb3",
      "4ee67a155499464fb2411aa97b8d6511",
      "1bd32910ce424ba8845a2b9720b7ad85",
      "d42713cc8e8c41978164e36dd4834d50",
      "1b9b08359d384b208965eefe7759e3e6",
      "ecc297de7a1a45df989ac2feb77d95d6",
      "a00b7d1b38a241bd821d3ab0478306b5",
      "26f392cc974b4d60a22e3a7e06285df6",
      "87898351e9a84ee6b866ab5bcb650af2",
      "eac7d26c37f443f9a8c7bcb4b558effe",
      "6253d8f136324ebb8713fdbc3059a7d8",
      "067308134ba3493990b5ad8df0c9571b"
     ]
    },
    "id": "vQVPUi4hhoBZ",
    "outputId": "d57b07c4-19ac-4de7-bcb1-21ec670b0b6d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a4949bd0974c0190deb7ccac382268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/332 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541d354512d34c3abdc4eb3c980f9472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f518092e824ed6a48235a3e91b278f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1595ec16b4440080b124c54954bd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc109d7338be40c0b8d3c7fd9e88db3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559af10a0c654a1695a7bf1f3eeedf92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee67a155499464fb2411aa97b8d6511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” åŒä¹‰è¯å¢å¼º: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10189/10189 [00:01<00:00, 5869.72it/s]\n",
      "ğŸ”„ è¯­ä¹‰æ”¹å†™å¢å¼º: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 637/637 [36:37<00:00,  3.45s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import wordnet\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# âœ… è½½å…¥æ›´å¿«çš„æ¨¡å‹ (æ”¯æŒ GPU + FP16)\n",
    "model_name = \"eugenesiow/bart-paraphrase\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).half().cuda()\n",
    "model.eval()\n",
    "\n",
    "# âœ… åŒä¹‰è¯æ›¿æ¢å‡½æ•°ï¼ˆä¸å˜ï¼‰\n",
    "def synonym_replacement(text, n=2):\n",
    "    words = text.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if word.isalpha()]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    for word in random_word_list:\n",
    "        synonyms = set()\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                synonym = lemma.name().replace(\"_\", \" \").lower()\n",
    "                if synonym != word and synonym.isalpha():\n",
    "                    synonyms.add(synonym)\n",
    "        if synonyms:\n",
    "            synonym = random.choice(list(synonyms))\n",
    "            new_words = [synonym if w == word else w for w in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "# âœ… æ‰¹é‡ paraphrase å‡½æ•°\n",
    "def batch_paraphrase(texts, max_length=128):\n",
    "    prompts = [f\"paraphrase: {t}\" for t in texts]\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            num_beams=5,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "# âœ… æ•°æ®å¢å¼ºæµç¨‹\n",
    "def augment_dataframe(df, batch_size=16):\n",
    "    augmented_rows = []\n",
    "\n",
    "    # åŒä¹‰è¯æ›¿æ¢éƒ¨åˆ†\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"ğŸ” åŒä¹‰è¯å¢å¼º\"):\n",
    "        q = row[\"Question\"]\n",
    "        label = row[\"label\"]\n",
    "        syn_q = synonym_replacement(q, n=2)\n",
    "        augmented_rows.append({\"Question\": syn_q, \"label\": label})\n",
    "\n",
    "    # è¯­ä¹‰æ”¹å†™éƒ¨åˆ†ï¼ˆbatchï¼‰\n",
    "    for i in tqdm(range(0, len(df), batch_size), desc=\"ğŸ”„ è¯­ä¹‰æ”¹å†™å¢å¼º\"):\n",
    "        batch_df = df.iloc[i:i+batch_size]\n",
    "        questions = batch_df[\"Question\"].tolist()\n",
    "        labels = batch_df[\"label\"].tolist()\n",
    "        try:\n",
    "            paraphrased = batch_paraphrase(questions)\n",
    "        except Exception as e:\n",
    "            print(f\"paraphrasing batch failed at [{i}-{i+batch_size}]: {e}\")\n",
    "            paraphrased = questions  # fallback\n",
    "\n",
    "        for new_q, label in zip(paraphrased, labels):\n",
    "            augmented_rows.append({\"Question\": new_q, \"label\": label})\n",
    "\n",
    "    df_aug = pd.DataFrame(augmented_rows)\n",
    "    df_combined = pd.concat([df, df_aug], ignore_index=True)\n",
    "    return df_combined\n",
    "\n",
    "# âœ… ç”¨æ³•ç¤ºä¾‹\n",
    "df = df_train\n",
    "df_augmented = augment_dataframe(df, batch_size=16)\n",
    "df_augmented.to_csv(\"augmented_math_questions.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6evx11K3RPsz",
    "outputId": "b92fa2a9-365d-482e-e420-9c46a2bf814c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¸…ç†å®Œæˆï¼Œä¿å­˜è‡³ augmented_math_questions_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ğŸ” è¯»å–ä½ ä¹‹å‰ä¿å­˜çš„å¢å¼ºæ•°æ®æ–‡ä»¶ï¼ˆCSV æˆ– TSVï¼‰\n",
    "# å¦‚æœæ˜¯ CSVï¼Œä½¿ç”¨ encoding=\"utf-8\" æˆ–é€‚é…ä½ ä¿å­˜æ—¶çš„ç¼–ç \n",
    "df = pd.read_csv(\"augmented_math_questions.csv\")  # æˆ–ä½ çš„å…·ä½“æ–‡ä»¶è·¯å¾„\n",
    "\n",
    "# âœ… å»é™¤å‰ç¼€ \"Paraphrase:\"ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰\n",
    "df[\"Question\"] = df[\"Question\"].str.replace(r\"(?i)^paraphrase:\\s*\", \"\", regex=True).str.strip()\n",
    "\n",
    "# ğŸ’¾ ä¿å­˜æ¸…ç†åçš„æ•°æ®\n",
    "df.to_csv(\"augmented_math_questions_cleaned.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"âœ… æ¸…ç†å®Œæˆï¼Œä¿å­˜è‡³ augmented_math_questions_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_e8WcSZ0hp8w"
   },
   "outputs": [],
   "source": [
    "# ========== Step 2. æ¨¡å‹å‚æ•° ==========\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "PATIENCE = 3\n",
    "MAX_LEN = 128\n",
    "FOLDS = 5\n",
    "LAMBDA = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hIqarB2thsCG"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# æ›¿æ¢ä¸ºä½ çš„ Huggingface Token\n",
    "login(\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8kv1irFhtko",
    "outputId": "ba8af19f-d52b-4840-94d3-4a9224434e8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class MathDataset(Dataset):\n",
    "    def __init__(self, questions, labels=None):\n",
    "        self.questions = [\"Classify the topic of this math problem: \" + q for q in questions]\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = tokenizer(self.questions[idx], padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "        item = {key: val.squeeze(0) for key, val in enc.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cwxzbAV-hvDg"
   },
   "outputs": [],
   "source": [
    "class MathClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(MODEL_NAME)\n",
    "        hidden_size = self.backbone.config.hidden_size\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, 8)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls = out.last_hidden_state[:, 0]  # [CLS] token\n",
    "        logits = self.fc(cls)\n",
    "        return logits, cls  # âœ… åŒæ—¶è¿”å› logits å’Œ features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ADH8Da9SDba",
    "outputId": "5276893e-6448-43b4-a639-458d4c5b7e4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30567, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3M_9Cgt3hxtQ",
    "outputId": "39f64a0f-d73e-4486-d998-07c02d802a73"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:15<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss: 1199.2723, Acc: 0.7092\n",
      "Epoch 1 Val Acc: 0.8413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:15<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train Loss: 856.8987, Acc: 0.8770\n",
      "Epoch 2 Val Acc: 0.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:15<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train Loss: 734.9760, Acc: 0.9260\n",
      "Epoch 3 Val Acc: 0.9339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:15<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Train Loss: 665.4672, Acc: 0.9552\n",
      "Epoch 4 Val Acc: 0.9467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:15<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Train Loss: 633.7081, Acc: 0.9674\n",
      "Epoch 5 Val Acc: 0.9522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:15<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Train Loss: 612.2776, Acc: 0.9758\n",
      "Epoch 6 Val Acc: 0.9552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:15<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Train Loss: 593.4011, Acc: 0.9827\n",
      "Epoch 7 Val Acc: 0.9627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:15<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Train Loss: 588.5134, Acc: 0.9850\n",
      "Epoch 8 Val Acc: 0.9598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:14<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Train Loss: 579.4239, Acc: 0.9883\n",
      "Epoch 9 Val Acc: 0.9702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:14<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train Loss: 572.7329, Acc: 0.9904\n",
      "Epoch 10 Val Acc: 0.9679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:15<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Train Loss: 569.3593, Acc: 0.9923\n",
      "Epoch 11 Val Acc: 0.9738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:15<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Train Loss: 565.1066, Acc: 0.9935\n",
      "Epoch 12 Val Acc: 0.9621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:15<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Train Loss: 564.3388, Acc: 0.9935\n",
      "Epoch 13 Val Acc: 0.9660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 860/860 [03:15<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Train Loss: 561.5693, Acc: 0.9944\n",
      "Epoch 14 Val Acc: 0.9728\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "# ========== Step 5. Hold-out + è®­ç»ƒ ==========\n",
    "\n",
    "all_questions = df[\"Question\"].tolist()\n",
    "all_labels = df[\"label\"].tolist()\n",
    "all_dataset = MathDataset(all_questions, all_labels)\n",
    "\n",
    "# ç®€å•åˆ’åˆ† 90% è®­ç»ƒé›† + 10% éªŒè¯é›†\n",
    "train_size = int(0.9 * len(all_dataset))\n",
    "val_size = len(all_dataset) - train_size\n",
    "train_ds, val_ds = torch.utils.data.random_split(all_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = MathClassifier().to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-5)\n",
    "loss_cls = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=EPOCHS * len(train_loader))\n",
    "\n",
    "def supervised_contrastive_loss(features, labels):\n",
    "    features = nn.functional.normalize(features, dim=1)\n",
    "    labels = labels.contiguous().view(-1, 1)\n",
    "    mask = torch.eq(labels, labels.T).float().to(DEVICE)\n",
    "    logits = torch.matmul(features, features.T) / 0.07\n",
    "    logits_mask = torch.ones_like(mask) - torch.eye(mask.size(0)).to(DEVICE)\n",
    "    mask = mask * logits_mask\n",
    "    exp_logits = torch.exp(logits) * logits_mask\n",
    "    log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-12)\n",
    "    mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-12)\n",
    "    return -mean_log_prob_pos.mean()\n",
    "\n",
    "best_acc = 0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, preds, trues = 0, [], []\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Train\"):\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "        logits, features = model(input_ids, attention_mask)\n",
    "        loss = loss_cls(logits, labels) + LAMBDA * supervised_contrastive_loss(features, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds.extend(logits.argmax(dim=1).cpu().tolist())\n",
    "        trues.extend(labels.cpu().tolist())\n",
    "\n",
    "    train_acc = accuracy_score(trues, preds)\n",
    "    print(f\"Epoch {epoch+1} Train Loss: {total_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "\n",
    "    # éªŒè¯\n",
    "    model.eval()\n",
    "    val_preds, val_trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "            logits, _ = model(input_ids, attention_mask)\n",
    "            val_preds.extend(logits.argmax(dim=1).cpu().tolist())\n",
    "            val_trues.extend(labels.cpu().tolist())\n",
    "\n",
    "    val_acc = accuracy_score(val_trues, val_preds)\n",
    "    print(f\"Epoch {epoch+1} Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), f\"best_model.pt\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lx8gYkSZsBF4",
    "outputId": "1c4b730f-ed0b-4173-e337-72d93940bc98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Step 8: ä½¿ç”¨å¢å¼ºæ¨¡å‹é¢„æµ‹ test.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:07<00:00, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æäº¤æ–‡ä»¶å·²ç”Ÿæˆ submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========== Step 8. æœ€ç»ˆé¢„æµ‹ ==========\n",
    "print(\"ğŸ§  Step 8: ä½¿ç”¨å¢å¼ºæ¨¡å‹é¢„æµ‹ test.csv...\")\n",
    "model.load_state_dict(torch.load(\"/content/best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "test_dataset = MathDataset(df_test['Question'].tolist())\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "final_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        if isinstance(outputs, tuple):\n",
    "            logits = outputs[0]\n",
    "        else:\n",
    "            logits = outputs\n",
    "\n",
    "        final_preds.extend(logits.argmax(dim=1).cpu().tolist())\n",
    "\n",
    "submission = pd.DataFrame({\"id\": df_test.index, \"label\": final_preds})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"âœ… æäº¤æ–‡ä»¶å·²ç”Ÿæˆ submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87,
     "referenced_widgets": [
      "d8d293996d3f4970ab7a9c463713cec7",
      "26c97f8867ed410c95a2584535799d34",
      "2f177e94005e49438c5600526ec0222c",
      "99de0848b50f43e7b29ac799bc15cbf5",
      "66794c2a68484856bed0afc3d87753b5",
      "dfdb8e32fa6f46d0821d942499fe3cb4",
      "0e76c8e6ffa14ae9a649feec7e359ccc",
      "d1f0ee04d99c4209a6fb97bc1524e855",
      "c5920e5a1ef6462c84f5c2fd26f992bb",
      "92487c3d32fd43619080147ebf713775",
      "3750e2596d9e4275b8f3478459c1c821"
     ]
    },
    "id": "-e6MdYFusfiS",
    "outputId": "c3254103-0004-4403-99f4-d4320dd26173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Step 6: ä½¿ç”¨ best_mathbert.pt ç”Ÿæˆä¼ªæ ‡ç­¾...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d293996d3f4970ab7a9c463713cec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä¼ªæ ‡ç­¾ç”Ÿæˆå®Œæ¯•ï¼Œå¢å¼ºåçš„è®­ç»ƒé›†æ ·æœ¬æ•°: 20400\n"
     ]
    }
   ],
   "source": [
    "# ========== Step 6. ä½¿ç”¨ best_mathbert.pt ç”Ÿæˆä¼ªæ ‡ç­¾ ==========\n",
    "print(\"ğŸ” Step 6: ä½¿ç”¨ best_mathbert.pt ç”Ÿæˆä¼ªæ ‡ç­¾...\")\n",
    "model.load_state_dict(torch.load(\"/content/best_model.pt\", map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "pseudo_dataset = MathDataset(df_test['Question'].tolist(), labels=None)  # æ˜ç¡® labels=None\n",
    "pseudo_loader = DataLoader(pseudo_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "final_preds = []\n",
    "probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(pseudo_loader, desc=\"Predicting\"):\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        logits, _ = model(input_ids, attention_mask)  # è§£åŒ… tuple è¾“å‡º\n",
    "        prob = torch.softmax(logits, dim=1)\n",
    "        probs.extend(prob.cpu().tolist())\n",
    "        final_preds.extend(prob.argmax(dim=1).cpu().tolist())\n",
    "\n",
    "df_test[\"label\"] = final_preds\n",
    "df_test[\"max_prob\"] = [np.max(p) for p in probs]\n",
    "filtered = df_test[df_test[\"max_prob\"] > 0.95]\n",
    "\n",
    "aug_df = pd.concat([df, filtered[[\"Question\", \"label\"]]], ignore_index=True)\n",
    "print(\"âœ… ä¼ªæ ‡ç­¾ç”Ÿæˆå®Œæ¯•ï¼Œå¢å¼ºåçš„è®­ç»ƒé›†æ ·æœ¬æ•°:\", len(aug_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHwqMXVOtT3p",
    "outputId": "a7c744ae-cd75-4a12-bafc-916a95f7852e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542,
     "referenced_widgets": [
      "2338b1412c8d480e8efb0d11fa93b050",
      "81d7b7a252424b7296f314e0a86731b8",
      "d342e3353d9e4d548c6c2f9e2b007fed",
      "1d5ccb57eea24f6fba6d5d6ad7ee5224",
      "cf571219cf274c77bc818d12b754c16a",
      "82953202b851475796d381a56308d2b2",
      "0a0fc5f30f65436f949347fd1be8ef07",
      "bc934120efcf4e3580eb99062ab44f59",
      "291243b1498b45359e4336b82f26f725",
      "0d6d7bdce6a74f3183f4ff6841da8543",
      "ed0025b7303642afa0830b5232093284",
      "391a624bea994b0d8e5cff8271571d4e",
      "350f44d9045e4517a0db938e91e52aad",
      "5773d74746924b4dabb738f8c480528e",
      "6623289529834f29948bb776a291c2fd",
      "53c8e4cf93c64e2bbd3491d131fb1d26",
      "baa3062039844c5c8d2e10c3ce3a6278",
      "ce9f11ceb4f0480d8557bddc76ed1965",
      "f2dd99cde1e44217b435c5b684afd991",
      "c528a90e491c4e6c8e373e236de21150",
      "0dd0109d71bf46acb444eb6adc73d0de",
      "39feedf581aa4b18b73a6b2525610880",
      "131af503acac4fb1a8b943d583960f7a",
      "f7d637ee0cfd428c9baf826abd5d5e8c",
      "10747058fe2e4745b3aaf7c585119322",
      "2d64f18d08c949bfbd92ab6a7836a6a9",
      "5a6638795ce4475f9135101e124e829a",
      "7ce6d758e300415fb3f9ca8f4675a58e",
      "8dea30f502ed4aa98fcbae0e31ded95c",
      "dd30a09644874e3d90e92f634189c4b2",
      "0806ef91013a4369aa7d208974b733e7",
      "24b5db00334e42ffafbe656679f2df89",
      "c15eb091448b4cae8fafda93253b8a77",
      "0b8079afdd614f8fb34695bf34893177",
      "f7ae75f807964b5eadd85a5b983b8bcc",
      "e9348eb5d3c64544b2e2d3b46b8e974f",
      "cad4f750b49a432baf20be6019a6c40b",
      "bfe82b1c284740b6aea46a576bae6573",
      "81318c9d26314f62be35c06d835c784e",
      "ae49742a2362499da6c5a6f74913667d",
      "69eb7dc1c0dd4a0fa343f39704efaf7c",
      "8d3d5953ef514da1b019f7cac0202186",
      "43bb72efc8c640de9b0b54b0d22097bd",
      "a8a8e2f7059744f8a26d61fcb3cb2eec",
      "f86bb17460aa45d5a679946a58012ad2",
      "45d4e0391af446de9145baf3e662656f",
      "88f4bb3422f341f9ad999121dbb60d45",
      "fccfd967dc7b4211b3c6a1dd47e30dee",
      "62f7f80f5dc14c1abbd41285a9de6969",
      "f2ab81d50cb6446d9b48497c1fd290e5",
      "985d1cd44fa34423897174a1553c32a4",
      "832a770d93354856b9a452260f3303d2",
      "7bc56075a91f4fad8847b68414585f2e",
      "622ee83efb284ffb929937544ae60f3f",
      "d46f1c0acb2641178897c52f0391f328",
      "8c03b88ddf694c15b31ce477d4ae5561",
      "36e15a9153954f64a45c16df5182f0ed",
      "ee801be35a954dedbce08d596bd852d8",
      "e0ac05e23a1d45d687d0f48bacaca040",
      "a9b319725a114a949379cf544d894920",
      "061e6aa99a974d6ba5a8f80c4fb872d9",
      "3df6bdcd49024d8e9aebf392775b6f00",
      "737cfd9775a44292b560b5ce46316629",
      "5f35c971862a4f3fae43ab4e6d246f17",
      "5f232a60aa0c49f187fb3547b8eacc05",
      "ce36a46962cb4bf793d36f7a756b354f",
      "7c05d10817a9446d822561459a05b989",
      "984db77964bf4218bce9f10137a1fdd3",
      "975777d44e3340e287d67663a0f8af17",
      "6323e3c5353e4969bd81372f45af627a",
      "cf884487b85b40c588ab0c48cee8abe2",
      "3cdb66d137ef47499df2b70bee021c30",
      "b73b949e7d5a450da16eca258c1a6385",
      "1452f433262747868dcb3b8cf4d7e3fc",
      "78a9d7b5a23d430bb54134773dd15934",
      "0328e44c496f416584f854b1accf2d59",
      "c5bb20fa1cf34a52995a5b496b47980f"
     ]
    },
    "id": "s61XE8rasimw",
    "outputId": "1315e05a-258c-48ea-e11d-d59b90fcbff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’ª Step 7: ä½¿ç”¨ä¼ªæ ‡ç­¾å¢å¼ºé‡æ–°è®­ç»ƒ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2338b1412c8d480e8efb0d11fa93b050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Train:   0%|          | 0/1148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss: 745.9100, Acc: 0.9724\n",
      "Epoch 1 Val Acc: 0.9794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391a624bea994b0d8e5cff8271571d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Train:   0%|          | 0/1148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train Loss: 717.0124, Acc: 0.9797\n",
      "Epoch 2 Val Acc: 0.9770\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131af503acac4fb1a8b943d583960f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Train:   0%|          | 0/1148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train Loss: 708.3229, Acc: 0.9829\n",
      "Epoch 3 Val Acc: 0.9863\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8079afdd614f8fb34695bf34893177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Train:   0%|          | 0/1148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Train Loss: 705.8056, Acc: 0.9832\n",
      "Epoch 4 Val Acc: 0.9882\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86bb17460aa45d5a679946a58012ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Train:   0%|          | 0/1148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Train Loss: 691.6933, Acc: 0.9879\n",
      "Epoch 5 Val Acc: 0.9833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c03b88ddf694c15b31ce477d4ae5561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 Train:   0%|          | 0/1148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Train Loss: 689.0345, Acc: 0.9885\n",
      "Epoch 6 Val Acc: 0.9877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c05d10817a9446d822561459a05b989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 Train:   0%|          | 0/1148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Train Loss: 677.4004, Acc: 0.9917\n",
      "Epoch 7 Val Acc: 0.9863\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "# ========== Step 7. å¢å¼ºè®­ç»ƒé›†å†æ¬¡è®­ç»ƒ ==========\n",
    "print(\"ğŸ’ª Step 7: ä½¿ç”¨ä¼ªæ ‡ç­¾å¢å¼ºé‡æ–°è®­ç»ƒ...\")\n",
    "\n",
    "dataset = MathDataset(aug_df[\"Question\"].tolist(), aug_df[\"label\"].tolist())\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"/content/best_model.pt\"))\n",
    "loss_cls = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=EPOCHS * len(train_loader))\n",
    "\n",
    "best_acc = 0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, preds, trues = 0, [], []\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Train\"):\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "        logits, features = model(input_ids, attention_mask)\n",
    "        loss = loss_cls(logits, labels) + LAMBDA * supervised_contrastive_loss(features, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds.extend(logits.argmax(dim=1).cpu().tolist())\n",
    "        trues.extend(labels.cpu().tolist())\n",
    "\n",
    "    train_acc = accuracy_score(trues, preds)\n",
    "    print(f\"Epoch {epoch+1} Train Loss: {total_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "\n",
    "    # éªŒè¯\n",
    "    model.eval()\n",
    "    val_preds, val_trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "            logits, _ = model(input_ids, attention_mask)\n",
    "            val_preds.extend(logits.argmax(dim=1).cpu().tolist())\n",
    "            val_trues.extend(labels.cpu().tolist())\n",
    "\n",
    "    val_acc = accuracy_score(val_trues, val_preds)\n",
    "    print(f\"Epoch {epoch+1} Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), f\"best_model.pt\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87,
     "referenced_widgets": [
      "5c0ecd377f5c412dbe94da416ad2367e",
      "632ed836bd0b480aa1af1ce0a37cbae3",
      "5e77cf5d84f348c08af00c1f746f4d24",
      "a528168cda3548768e81092b0af072e4",
      "4cf872c2615346c9a965eab03795d975",
      "01f681b723ac40ebad872ade4dfd2d55",
      "d963f36f887a4c5bbdd0160c0f3d7a04",
      "a0e04d986f0a4ff7b3f427892265c129",
      "cc60a069215c4db6b7e13d1bb85fa99e",
      "b23ae1480b0840d3b4c93126d06bd011",
      "85486c9b6df943d9a9f80dd44f322233"
     ]
    },
    "id": "lVAwjZZAymZB",
    "outputId": "952e2579-f4cd-45a9-9093-264ed9f7d655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Step 8: ä½¿ç”¨å¢å¼ºæ¨¡å‹é¢„æµ‹ test.csv...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0ecd377f5c412dbe94da416ad2367e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æäº¤æ–‡ä»¶å·²ç”Ÿæˆ submission.csv\n"
     ]
    }
   ],
   "source": [
    "# ========== Step 8. æœ€ç»ˆé¢„æµ‹ ==========\n",
    "print(\"ğŸ§  Step 8: ä½¿ç”¨å¢å¼ºæ¨¡å‹é¢„æµ‹ test.csv...\")\n",
    "model.load_state_dict(torch.load(\"/content/best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "test_dataset = MathDataset(df_test['Question'].tolist())\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "final_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        if isinstance(outputs, tuple):\n",
    "            logits = outputs[0]\n",
    "        else:\n",
    "            logits = outputs\n",
    "\n",
    "        final_preds.extend(logits.argmax(dim=1).cpu().tolist())\n",
    "\n",
    "submission = pd.DataFrame({\"id\": df_test.index, \"label\": final_preds})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"âœ… æäº¤æ–‡ä»¶å·²ç”Ÿæˆ submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
